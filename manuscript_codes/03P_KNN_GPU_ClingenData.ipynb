{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894a7d7f-c211-496a-9e56-96322a2457cb",
   "metadata": {},
   "source": [
    "# Import Clingen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc0787-6637-4fe7-8804-7f5a770bfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_column = [\n",
    "    'SIFT_score', \n",
    "    'FATHMM_score', \n",
    "    'VEST4_score', \n",
    "    'REVEL_score',\n",
    "    'GERP++_RS', \n",
    "    'phyloP100way_vertebrate', \n",
    "    'EA_1.0',\n",
    "    'BayesDel_nsfp33a_noAF', \n",
    "    'MutPred2.0_score', \n",
    "    'CADDv1.6_PHRED',\n",
    "    'pph2_prob', \n",
    "    'MPC_score', \n",
    "    'PrimateAI_score',\n",
    "    'ClinVar_annotation'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ad13d-8ae7-46d7-9594-dd804f9c2890",
   "metadata": {},
   "source": [
    "## ClinVar 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e67f3e-fab1-4443-830f-e65ae216061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ClinVar_2019 = pd.read_csv(\"/gpfs/home/pl2948/VariantInterpretation/Data/ClinVar2019Set.csv\")\n",
    "ClinVar_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afbdef-68da-4952-a490-df5f09a98502",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data = ClinVar_2019.rename(columns={'clnsig': 'ClinVar_annotation'})\n",
    "del ClinVar_2019\n",
    "\n",
    "ClinVar_ann = {\n",
    "    'Benign/Likely_benign': 0, \n",
    "    'Likely_benign': 0, \n",
    "    'Pathogenic': 1,\n",
    "    'Likely_pathogenic': 1, \n",
    "    'Benign': 0, \n",
    "    'Pathogenic/Likely_pathogenic': 1\n",
    "    }\n",
    "\n",
    "calibration_data['ClinVar_annotation'] = calibration_data['ClinVar_annotation'].map(ClinVar_ann)\n",
    "calibration_data = calibration_data[calibration_data['ClinVar_annotation'].notna()]\n",
    "# calibration_data = calibration_data[calibration_data['hg19_chr']!='MT']\n",
    "calibration_data = calibration_data[select_column]\n",
    "\n",
    "print(len(calibration_data))\n",
    "\n",
    "for col in select_column[:-1]:\n",
    "    calibration_data[col] = pd.to_numeric(calibration_data[col], errors='coerce')\n",
    "    if col in ['SIFT_score', 'FATHMM_score']:\n",
    "        calibration_data[col] *=-1\n",
    "\n",
    "calibration_data = calibration_data.reset_index(drop=True)\n",
    "\n",
    "display(calibration_data)\n",
    "print(calibration_data.isna().sum()/len(calibration_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de06ee4-26de-4898-8d5f-d691653bae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pathogenic\", sum(calibration_data['ClinVar_annotation']==1))\n",
    "print(\"Benign\", sum(calibration_data['ClinVar_annotation']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aef0f-6644-4078-a458-8a230b8547c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_roc_and_auc(y_true, y_score, label):\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "\n",
    "    valid_indices = ~np.isnan(y_score) & ~np.isnan(y_true)\n",
    "    y_true_cleaned = y_true[valid_indices]\n",
    "    y_score_cleaned = y_score[valid_indices]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true_cleaned, y_score_cleaned)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return fpr, tpr, roc_auc, label\n",
    "\n",
    "def calculate_MI(y_true, y_score):\n",
    "    y_true = np.array(y_true)\n",
    "    y_score = np.array(y_score)\n",
    "\n",
    "    valid_indices = ~np.isnan(y_score) & ~np.isnan(y_true)\n",
    "    y_score = np.array(y_score).reshape(-1, 1)\n",
    "    y_true_cleaned = y_true[valid_indices]\n",
    "    y_score_cleaned = y_score[valid_indices]\n",
    "\n",
    "    mutual_information = mutual_info_classif(y_score_cleaned, y_true_cleaned)\n",
    "    return mutual_information[0]\n",
    "\n",
    "    \n",
    "roc_curves = []\n",
    "AUC = []\n",
    "MI = []\n",
    "\n",
    "for col in select_column[:-1]:  # Exclude 'ClinVar_annotation'\n",
    "    roc_curves.append(calculate_roc_and_auc(\n",
    "        calibration_data['ClinVar_annotation'], calibration_data[col], col))\n",
    "    MI.append(calculate_MI(calibration_data['ClinVar_annotation'], calibration_data[col]))\n",
    "\n",
    "# Plot ROC curves\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for fpr, tpr, roc_auc, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "    AUC.append(roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Reference diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(MI, AUC)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b4a1d-5ffe-4d34-8d3b-02be5da13fab",
   "metadata": {},
   "source": [
    "## ClinVar 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bc1fd-c376-4613-8893-380796206c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ClinVar_2020 = pd.read_csv(\"/gpfs/home/pl2948/VariantInterpretation/Data/ClinVar2020Set.csv\")\n",
    "ClinVar_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d848e56-c5ee-4207-8f23-0b161febe42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ClinVar_2020.rename(columns={'clnsig': 'ClinVar_annotation'})\n",
    "del ClinVar_2020\n",
    "\n",
    "ClinVar_ann = {\n",
    "    'Benign/Likely_benign': 0, \n",
    "    'Likely_benign': 0, \n",
    "    'Pathogenic': 1,\n",
    "    'Likely_pathogenic': 1, \n",
    "    'Benign': 0, \n",
    "    'Pathogenic/Likely_pathogenic': 1\n",
    "    }\n",
    "\n",
    "test_data['ClinVar_annotation'] = test_data['ClinVar_annotation'].map(ClinVar_ann)\n",
    "test_data = test_data[test_data['ClinVar_annotation'].notna()]\n",
    "test_data = test_data[select_column]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "for col in select_column[:-1]:\n",
    "    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
    "    if col in ['SIFT_score', 'FATHMM_score']:\n",
    "        test_data[col] *=-1\n",
    "\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "display(test_data)\n",
    "print(test_data.isna().sum()/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b12bef-793d-4fcc-abf7-4c864c05ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pathogenic\", sum(test_data['ClinVar_annotation']==1))\n",
    "print(\"Benign\", sum(test_data['ClinVar_annotation']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a5a3d-c34d-4807-8279-c6eb5b423da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc_curves = []\n",
    "\n",
    "for col in select_column[:-1]:  # Exclude 'ClinVar_annotation'\n",
    "    roc_curves.append(calculate_roc_and_auc(\n",
    "        test_data['ClinVar_annotation'], test_data[col], col))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for fpr, tpr, roc_auc, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Reference diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161e4e0-f265-4262-8321-5b823cd10896",
   "metadata": {},
   "source": [
    "## gnomAD set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e8f71c-478a-47fc-9d45-b18d04e5411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gnomAD_set = pd.read_csv(\"/gpfs/home/pl2948/VariantInterpretation/Data/GnomADSet.csv\")\n",
    "gnomAD_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35f31d-b73e-4ca6-be0a-514ec4df46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnomAD_set = gnomAD_set[select_column[:-1]]\n",
    "\n",
    "# print(len(gnomAD_set))\n",
    "\n",
    "for col in select_column[:-1]:\n",
    "    gnomAD_set[col] = pd.to_numeric(gnomAD_set[col], errors='coerce')\n",
    "    # gnomAD_set = gnomAD_set[(gnomAD_set[col]!='.') & (gnomAD_set[col].notna())]\n",
    "    # print(col, len(gnomAD_set))\n",
    "    if col in ['SIFT_score', 'FATHMM_score']:\n",
    "        gnomAD_set[col] *=-1\n",
    "\n",
    "gnomAD_set = gnomAD_set.reset_index(drop=True)\n",
    "    \n",
    "display(gnomAD_set)\n",
    "print(gnomAD_set.isna().sum()/len(gnomAD_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c17e8-db73-4335-8981-cb9b2251f2c2",
   "metadata": {},
   "source": [
    "# Observing silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fce849-6188-41f3-8f18-746cf35df6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "select_column = [\n",
    "    'SIFT_score', \n",
    "    'FATHMM_score', \n",
    "    'VEST4_score', \n",
    "    'REVEL_score',\n",
    "    'GERP++_RS', \n",
    "    'phyloP100way_vertebrate', \n",
    "    'EA_1.0',\n",
    "    'BayesDel_nsfp33a_noAF', \n",
    "    'MutPred2.0_score', \n",
    "    'CADDv1.6_PHRED',\n",
    "    'pph2_prob', \n",
    "    'MPC_score', \n",
    "    'PrimateAI_score',\n",
    "    'ClinVar_annotation'\n",
    "]\n",
    "\n",
    "calibration_feature = calibration_data[select_column[:-1]].to_numpy()\n",
    "test_feature = test_data[select_column[:-1]].to_numpy()\n",
    "regularization_feature = gnomAD_set[select_column[:-1]].to_numpy()\n",
    "\n",
    "calibration_label = calibration_data[select_column[-1]].to_numpy()\n",
    "calibration_label_bk = copy.deepcopy(calibration_label)\n",
    "test_label = test_data[select_column[-1]].to_numpy()\n",
    "test_label_bk = copy.deepcopy(test_label)\n",
    "\n",
    "print(calibration_feature.shape, test_feature.shape, regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e635c7-ae3d-4945-be2c-6460087561d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from P_KNN_GPU import silhouette_score_1d_torch, get_score_rank_torch\n",
    "\n",
    "calibration_feature_rank = get_score_rank_torch(torch.tensor(calibration_feature), torch.tensor(calibration_feature))\n",
    "\n",
    "for i in range(len(select_column)-1): \n",
    "    select_feature = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = torch.tensor(calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1))\n",
    "    calibration_array_rank = calibration_feature_rank[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = torch.tensor(copy.deepcopy(calibration_label_bk[valid_calibration_idx]))\n",
    "\n",
    "    print(f\"Tool {select_column[i]}, calibration size: {calibration_array.shape[0]}\")\n",
    "    silhouette_raw = silhouette_score_1d_torch(calibration_array, calibration_label)\n",
    "    silhouette_rank = silhouette_score_1d_torch(calibration_array_rank, calibration_label)\n",
    "    print('silhouette_raw', silhouette_raw)\n",
    "    print('silhouette_rank', silhouette_rank)\n",
    "\n",
    "    red_mask = calibration_label == 1\n",
    "    blue_mask = calibration_label == 0\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    axes[0].hist(calibration_array[red_mask], bins=30, color='red', alpha=0.6, label='Label 1')\n",
    "    axes[0].hist(calibration_array[blue_mask], bins=30, color='blue', alpha=0.6, label='Label 0')\n",
    "    axes[0].set_title(f\"Histogram of {select_column[i]}\")\n",
    "    axes[0].set_xlabel(\"Calibration Array Values\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].hist(calibration_array_rank[red_mask], bins=30, color='red', alpha=0.6, label='Label 1')\n",
    "    axes[1].hist(calibration_array_rank[blue_mask], bins=30, color='blue', alpha=0.6, label='Label 0')\n",
    "    axes[1].set_title(f\"Histogram of Ranked {select_column[i]}\")\n",
    "    axes[1].set_xlabel(\"Calibration Array Rank Values\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d14acb-27c9-4518-b173-d28be89b3c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [2,3,7,8]: \n",
    "    select_feature = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:,select_feature]) \n",
    "    test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "    test_label = copy.deepcopy(test_label_bk[valid_test_idx])\n",
    "\n",
    "    print(f\"Tool {select_column[i]}, calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    red_mask_calibration = calibration_label == 1\n",
    "    blue_mask_calibration = calibration_label == 0\n",
    "\n",
    "    red_mask_test = test_label == 1\n",
    "    blue_mask_test = test_label == 0\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.hist(calibration_array[red_mask_calibration], bins=30, color='red', alpha=0.6, label='Calibration-Pathogenic', density=True)\n",
    "    plt.hist(calibration_array[blue_mask_calibration], bins=30, color='blue', alpha=0.6, label='Calibration-Benign', density=True)\n",
    "    plt.hist(test_array[red_mask_test], bins=30, color='orange', alpha=0.3, label='Test-Pathogenic', density=True)\n",
    "    plt.hist(test_array[blue_mask_test], bins=30, color='cyan', alpha=0.3, label='Test-Benign', density=True)\n",
    "    # ax = plt.gca()\n",
    "    plt.title(f\"Histogram of calibration dataset {select_column[i]}\")\n",
    "    plt.xlabel(\"Calibration Array Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    if select_column[i]=='BayesDel_nsfp33a_noAF': plt.legend(loc='upper left', fontsize = 14)\n",
    "    else: plt.legend(loc='upper center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/gpfs/home/pl2948/VariantInterpretation/KNNCode/{select_column[i]}_distribution.svg\", format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4c4fa-30bf-4d67-ae64-41b4d0ca74bc",
   "metadata": {},
   "source": [
    "# Single Tool 1D calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75de12-7f4b-480d-b1a5-4dd3ed507ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "select_column = [\n",
    "    'SIFT_score', \n",
    "    'FATHMM_score', \n",
    "    'VEST4_score', \n",
    "    'REVEL_score',\n",
    "    'GERP++_RS', \n",
    "    'phyloP100way_vertebrate', \n",
    "    'EA_1.0',\n",
    "    'BayesDel_nsfp33a_noAF', \n",
    "    'MutPred2.0_score', \n",
    "    'CADDv1.6_PHRED',\n",
    "    'pph2_prob', \n",
    "    'MPC_score', \n",
    "    'PrimateAI_score',\n",
    "    'ClinVar_annotation'\n",
    "]\n",
    "\n",
    "calibration_feature = calibration_data[select_column[:-1]].to_numpy()\n",
    "test_feature = test_data[select_column[:-1]].to_numpy()\n",
    "regularization_feature = gnomAD_set[select_column[:-1]].to_numpy()\n",
    "\n",
    "calibration_label = calibration_data[select_column[-1]].to_numpy()\n",
    "calibration_label_bk = copy.deepcopy(calibration_label)\n",
    "test_label = test_data[select_column[-1]].to_numpy()\n",
    "test_label_bk = copy.deepcopy(test_label)\n",
    "\n",
    "print(calibration_feature.shape, test_feature.shape, regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32f59c-5459-40c8-9e88-fd0c67b16dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score_1D, evaluate_result_1D\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441\n",
    "w_calibration=None\n",
    "n_calibration_in_window = 100\n",
    "frac_regularization_in_window=0.03\n",
    "batch_size = 512 \n",
    "normalization= None\n",
    "impute = False\n",
    "mi_scaling = False\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "best_mean_evidence_strength = 0\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in range(len(select_column)-1):    \n",
    "    condition_string = select_column[i]\n",
    "    select_feature = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:,select_feature])\n",
    "    test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "    test_label = copy.deepcopy(test_label_bk[valid_test_idx])\n",
    "\n",
    "    valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature])\n",
    "    regularization_array = regularization_feature[valid_regularization_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Tool {condition_string}\")\n",
    "    print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                     calibration_label, Pprior, w_calibration, \n",
    "                                                     n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                     normalization, impute, mi_scaling, n_bootstrap, batch_size)\n",
    "\n",
    "    np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_{condition_string}.npy', test_results_array)\n",
    "\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_{condition_string}.npy')\n",
    "\n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score_1D(test_results_array, test_array, p_value, Pprior, logbase)\n",
    "\n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result_1D(test_results_array,\n",
    "                                                                                                      test_array,\n",
    "                                                                                                      test_label, \n",
    "                                                                                                      p_value, \n",
    "                                                                                                      Pprior, \n",
    "                                                                                                      logbase, \n",
    "                                                                                                      category = condition_string, \n",
    "                                                                                                      show_plot=True, \n",
    "                                                                                                      save_name=condition_string)\n",
    "\n",
    "    test_data.loc[valid_test_idx, f\"P-KNN_Pathogenic_{condition_string}\"] = P_KNN_pathogenic\n",
    "\n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "    mean_evidence_strength = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean() + evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "    if mean_evidence_strength >  best_mean_evidence_strength:\n",
    "        best_mean_evidence_strength = mean_evidence_strength\n",
    "        best_tool = i\n",
    "        \n",
    "    print(\"pathogenic evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean():.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean():.3f}\")\n",
    "\n",
    "\n",
    "select_feature = best_tool\n",
    "condition_string = select_column[select_feature]\n",
    "\n",
    "valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "valid_test_idx = ~np.isnan(test_feature[:,select_feature])\n",
    "test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "test_label = copy.deepcopy(test_label_bk[valid_test_idx])\n",
    "\n",
    "valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature])\n",
    "regularization_array = regularization_feature[valid_regularization_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Best Tool {condition_string}\")\n",
    "print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_{condition_string}.npy')\n",
    "\n",
    "P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score_1D(test_results_array, test_array, p_value, Pprior, logbase)\n",
    "test_data.loc[valid_test_idx, f\"ACMGLLR_{condition_string}\"] = ACMG_scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d4f7b-9448-4f84-9cff-a1469cbf8e89",
   "metadata": {},
   "source": [
    "## Deal with miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778749e4-2fff-4b9c-9c4f-98fd7c1e5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# tool=\"MutPred2.0_score\"\n",
    "tool=\"BayesDel_nsfp33a_noAF\"\n",
    "# tool=\"VEST4_score\"\n",
    "# tool=\"REVEL_score\"\n",
    "\n",
    "upper = 0.3\n",
    "lower = 0.2\n",
    "\n",
    "x = test_data[tool]\n",
    "y = test_data[f'P-KNN_Pathogenic_{tool}']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x, y, alpha=0.6, c='purple', label='Variants')\n",
    "plt.xlabel(tool)\n",
    "plt.ylabel(f'Posterior Probability Pathogenic_{tool}')\n",
    "plt.title(f'Scatter Plot of {tool} vs. P-KNN')\n",
    "plt.grid(True)\n",
    "\n",
    "idx_05 = (np.abs(y - upper)).idxmin()\n",
    "idx_06 = (np.abs(y - lower)).idxmin()\n",
    "\n",
    "x_05 = x.loc[idx_05]\n",
    "x_06 = x.loc[idx_06]\n",
    "\n",
    "plt.scatter([x_05], [y.loc[idx_05]], color='orange', label='Closest to 0.5', zorder=5)\n",
    "plt.scatter([x_06], [y.loc[idx_06]], color='cyan', label='Closest to 0.6', zorder=5)\n",
    "\n",
    "plt.text(x_05, y.loc[idx_05], f\"{x_05:.3f}\", fontsize=9, ha='right')\n",
    "plt.text(x_06, y.loc[idx_06], f\"{x_06:.3f}\", fontsize=9, ha='right')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924860df-6d45-4ad8-ba49-34e1f36f6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "for i in [7]:\n",
    "    select_feature = i\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:, select_feature])\n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:, select_feature].reshape(-1, 1)\n",
    "    calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:, select_feature])\n",
    "    test_array = test_feature[valid_test_idx][:, select_feature].reshape(-1, 1)\n",
    "    test_label = copy.deepcopy(test_label_bk[valid_test_idx])\n",
    "\n",
    "    print(f\"Tool {select_column[i]}, calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    red_mask_calibration = calibration_label == 1\n",
    "    blue_mask_calibration = calibration_label == 0\n",
    "    red_mask_test = test_label == 1\n",
    "    blue_mask_test = test_label == 0\n",
    "\n",
    "    combined_values = np.concatenate([\n",
    "        calibration_array[red_mask_calibration].ravel(),\n",
    "        calibration_array[blue_mask_calibration].ravel(),\n",
    "        test_array[red_mask_test].ravel(),\n",
    "        test_array[blue_mask_test].ravel()\n",
    "    ])\n",
    "    bins = np.histogram_bin_edges(combined_values, bins=30)\n",
    "\n",
    "    colors = {\n",
    "        'Calibration-Pathogenic': 'red',\n",
    "        'Calibration-Benign': 'blue',\n",
    "        'Test-Pathogenic': '#cc6666',\n",
    "        'Test-Benign': '#339999',\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 6))\n",
    "    ax.hist(calibration_array[red_mask_calibration], bins=bins, color=colors['Calibration-Pathogenic'],\n",
    "            histtype='stepfilled', alpha=0.6, label='Calibration-pathogenic variants', density=True)\n",
    "    ax.hist(calibration_array[blue_mask_calibration], bins=bins, color=colors['Calibration-Benign'],\n",
    "            histtype='stepfilled', alpha=0.6, label='Calibration-benign variants', density=True)\n",
    "    ax.hist(test_array[red_mask_test], bins=bins, color=colors['Test-Pathogenic'],\n",
    "            histtype='stepfilled', alpha=0.3, label='Test-pathogenic variants', density=True)\n",
    "    ax.hist(test_array[blue_mask_test], bins=bins, color=colors['Test-Benign'],\n",
    "            histtype='stepfilled', alpha=0.3, label='Test-benign variants', density=True)\n",
    "\n",
    "    ax.set_xlabel(\"Feature Value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xticks([-1, -0.5, 0, 0.5])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    if select_column[i] == 'BayesDel_nsfp33a_noAF':\n",
    "        ax.legend(loc='upper left', fontsize=14, bbox_to_anchor=(0, 1.5))\n",
    "    else:\n",
    "        ax.legend(loc='upper center')\n",
    "\n",
    "    if select_column[i] == 'BayesDel_nsfp33a_noAF':\n",
    "        x_raw = test_data['BayesDel_nsfp33a_noAF'].values\n",
    "        x_knn = test_data['P-KNN_Pathogenic_BayesDel_nsfp33a_noAF'].values\n",
    "        valid_mask = ~np.isnan(x_raw) & ~np.isnan(x_knn)\n",
    "        x_raw = x_raw[valid_mask]\n",
    "        x_knn = x_knn[valid_mask]\n",
    "\n",
    "        desired_knn_scores = np.array([0.0, 0.01, 0.1, 0.4, 0.8])\n",
    "        matched_raw = []\n",
    "        for s in desired_knn_scores:\n",
    "            idx = np.abs(x_knn - s).argmin()\n",
    "            matched_raw.append(x_raw[idx])\n",
    "\n",
    "        ax_bottom = ax.twiny()\n",
    "        ax_bottom.set_xlim(ax.get_xlim())\n",
    "        ax_bottom.set_xticks(matched_raw)\n",
    "        ax_bottom.set_xticklabels([f\"{v:.2f}\" if v < 0.1 else f\"{v:.1f}\" for v in desired_knn_scores])\n",
    "        ax_bottom.set_xlabel(\"P-KNN Pathogenic Probability (BayesDel_nsfp33a_noAF)\", fontsize=11)\n",
    "\n",
    "        ax_bottom.xaxis.set_ticks_position('bottom')\n",
    "        ax_bottom.xaxis.set_label_position('bottom')\n",
    "        ax_bottom.spines['top'].set_visible(False)\n",
    "        ax_bottom.spines['right'].set_visible(False)\n",
    "        ax_bottom.spines['bottom'].set_position(('outward', 60))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/gpfs/home/pl2948/VariantInterpretation/KNNCode/{select_column[i]}_distribution_with_calibrated_ticks.svg\", format=\"svg\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1b141-3bf7-46b4-a15b-db9543441f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score_1D, evaluate_result_1D\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441\n",
    "w_calibration=None\n",
    "n_calibration_in_window = 100\n",
    "frac_regularization_in_window=0.03\n",
    "batch_size = 512 \n",
    "normalization= None\n",
    "impute = False\n",
    "mi_scaling = False\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "best_mean_evidence_strength = 0\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in [2, 3, 7, 8]:    \n",
    "    condition_string = select_column[i]\n",
    "    select_feature = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "    valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature])\n",
    "    regularization_array = regularization_feature[valid_regularization_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Tool {condition_string}\")\n",
    "    print(f\"calibration size: {calibration_array.shape[0]}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_calibrateset{condition_string}.npy')\n",
    "\n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score_1D(test_results_array, calibration_array, p_value, Pprior, logbase)\n",
    "\n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result_1D(test_results_array,\n",
    "                                                                                                      calibration_array,\n",
    "                                                                                                      calibration_label, \n",
    "                                                                                                      p_value, \n",
    "                                                                                                      Pprior, \n",
    "                                                                                                      logbase, \n",
    "                                                                                                      category = condition_string, \n",
    "                                                                                                      show_plot=True, \n",
    "                                                                                                      save_name=condition_string)\n",
    "\n",
    "    calibration_data.loc[valid_calibration_idx, f\"P-KNN_Pathogenic_{condition_string}\"] = P_KNN_pathogenic\n",
    "\n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "    print(\"pathogenic evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean():.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ceebc-9ccb-479c-9540-fa94f284d5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "Pprior = 0.0441\n",
    "\n",
    "for i in [7]:\n",
    "    if i=='P_KNN_pathogenic':\n",
    "        tool = i\n",
    "        score_tool = i\n",
    "    else:    \n",
    "        tool = select_column[i]\n",
    "        score_tool = f\"P-KNN_Pathogenic_{tool}\"\n",
    "\n",
    "    calibration_pathogenic = calibration_data[calibration_data['ClinVar_annotation'] == 1][score_tool].dropna()\n",
    "    calibration_benign = calibration_data[calibration_data['ClinVar_annotation'] == 0][score_tool].dropna()\n",
    "    test_pathogenic = test_data[test_data['ClinVar_annotation'] == 1][score_tool].dropna()\n",
    "    test_benign = test_data[test_data['ClinVar_annotation'] == 0][score_tool].dropna()\n",
    "\n",
    "    bins = np.linspace(0,1,11)\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "    cal_path_dens, _ = np.histogram(calibration_pathogenic, bins=bins, density=True)\n",
    "    test_path_dens, _ = np.histogram(test_pathogenic, bins=bins, density=True)\n",
    "    cal_ben_dens, _ = np.histogram(calibration_benign, bins=bins, density=True)\n",
    "    test_ben_dens, _ = np.histogram(test_benign, bins=bins, density=True)\n",
    "\n",
    "    calibration_prob = cal_path_dens*Pprior/(cal_path_dens*Pprior+cal_ben_dens*(1-Pprior))\n",
    "    test_prob = test_path_dens*Pprior/(cal_path_dens*Pprior+test_ben_dens*(1-Pprior))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    \n",
    "    ax.plot(bin_centers, calibration_prob, color='purple', label='Calibration dataset \\nnormalized % of pathogenic variants', linewidth=2, alpha=0.7)\n",
    "    ax.plot(bin_centers, test_prob, color='orchid', label='Test dataset \\nnormalized % of pathogenic variants', linewidth=2, alpha=0.7)\n",
    "    ax.set_ylabel(\"Normalized % of \\npathogenic variants\", fontsize=12)\n",
    "    ax.set_xlim([0, 1.05])\n",
    "    ax.set_xlabel(\"Posterior probability (pathogenic)\")\n",
    "    \n",
    "    ax.plot(bin_centers, calibration_prob-test_prob, color='orange', label='Difference (calibration - test) \\nnormalized % of pathogenic variants', linewidth=4, alpha=0.7)\n",
    "    \n",
    "    ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.5), fontsize=14)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/gpfs/home/pl2948/VariantInterpretation/KNNCode/{select_column[i]}_densityratio.svg\", format=\"svg\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cfce8-4590-465a-8114-309671e6b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_score_with_binom_ci(p_array, n_array, w, p_value=0.05):\n",
    "    from scipy.stats import binom\n",
    "    p_array = np.asarray(p_array)\n",
    "    n_array = np.asarray(n_array)\n",
    "    shape = p_array.shape\n",
    "\n",
    "    scores = np.full(shape, np.nan)\n",
    "    ci_lower = np.full(shape, np.nan)\n",
    "    ci_upper = np.full(shape, np.nan)\n",
    "\n",
    "    t_array = p_array + n_array\n",
    "\n",
    "    it = np.nditer(p_array, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        p = p_array[idx]\n",
    "        t = t_array[idx]\n",
    "\n",
    "        if t > 0:\n",
    "            pi_hat = p / t\n",
    "            ci_low, ci_up = binom.interval(1-p_value, t, pi_hat)\n",
    "            \n",
    "            def weighted(pi):\n",
    "                return pi / (pi + w * (1 - pi))\n",
    "\n",
    "            scores[idx] = weighted(pi_hat)\n",
    "            ci_lower[idx] = weighted(ci_low / t)\n",
    "            ci_upper[idx] = weighted(ci_up / t)\n",
    "        \n",
    "        it.iternext()\n",
    "    \n",
    "    return scores, ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb7004-1407-4399-a0d1-96cf653d1348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "Pprior = 0.0441\n",
    "logbase = 1124\n",
    "\n",
    "Post_p = np.zeros(4) \n",
    "Post_b = np.zeros(4)\n",
    "\n",
    "for j in range(4):\n",
    "    Post_p[j] = logbase ** (1 / 2 ** j) * Pprior / ((logbase ** (1 / 2 ** j) - 1) * Pprior + 1)\n",
    "    Post_b[j] = (logbase ** (1 / 2 ** j)) * (1 - Pprior) / (((logbase ** (1 / 2 ** j)) - 1) * (1 - Pprior) + 1)\n",
    "\n",
    "for i in [2, 3, 7, 8]:#, 'P_KNN_pathogenic']:\n",
    "    if i=='P_KNN_pathogenic':\n",
    "        tool = i\n",
    "        score_tool = i\n",
    "    else:    \n",
    "        tool = select_column[i]\n",
    "        score_tool = f\"P-KNN_Pathogenic_{tool}\"\n",
    "\n",
    "    calibration_pathogenic = calibration_data[calibration_data['ClinVar_annotation'] == 1][score_tool].dropna()\n",
    "    calibration_benign = calibration_data[calibration_data['ClinVar_annotation'] == 0][score_tool].dropna()\n",
    "    test_pathogenic = test_data[test_data['ClinVar_annotation'] == 1][score_tool].dropna()\n",
    "    test_benign = test_data[test_data['ClinVar_annotation'] == 0][score_tool].dropna()\n",
    "\n",
    "    w_test = (1 - Pprior) * len(test_pathogenic) / (len(test_benign) * Pprior) \n",
    "\n",
    "    bins = np.linspace(0,1,11)\n",
    "    bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio_path_dens = np.where(cal_path_dens != 0, test_path_dens / cal_path_dens, np.nan)\n",
    "        ratio_ben_dens = np.where(cal_ben_dens != 0, test_ben_dens / cal_ben_dens , np.nan)\n",
    "\n",
    "    pathogenic_counts, _ = np.histogram(test_pathogenic, bins=bins, density=False)\n",
    "    benign_counts, _ = np.histogram(test_benign, bins=bins, density=False)\n",
    "\n",
    "    pathogenic_ratios, ci_lower, ci_upper = weighted_score_with_binom_ci(pathogenic_counts, benign_counts, w_test, p_value=0.05)\n",
    "    valid_mask = ~np.isnan(pathogenic_ratios) & ~np.isnan(ci_lower) & ~np.isnan(ci_upper)\n",
    "\n",
    "    cal_path_dens, _ = np.histogram(calibration_pathogenic, bins=bins, density=True)\n",
    "    test_path_dens, _ = np.histogram(test_pathogenic, bins=bins, density=True)\n",
    "    cal_ben_dens, _ = np.histogram(calibration_benign, bins=bins, density=True)\n",
    "    test_ben_dens, _ = np.histogram(test_benign, bins=bins, density=True)\n",
    "\n",
    "    calibration_prob = cal_path_dens*Pprior/(cal_path_dens*Pprior+cal_ben_dens*(1-Pprior))\n",
    "    test_prob = test_path_dens*Pprior/(cal_path_dens*Pprior+test_ben_dens*(1-Pprior))\n",
    "\n",
    "    valid_mask = ~np.isnan(pathogenic_ratios) & ~np.isnan(ci_lower) & ~np.isnan(ci_upper)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 5.45))\n",
    "\n",
    "    ax1.plot(bin_centers[valid_mask], pathogenic_ratios[valid_mask], \n",
    "             'o-', color='red', label='Frequency of pathogenic variants')\n",
    "    ax1.fill_between(bin_centers[valid_mask], \n",
    "                     ci_lower[valid_mask], ci_upper[valid_mask], \n",
    "                     color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "    ax1.set_ylabel(\"Pathogenic Probability\", fontsize=12)\n",
    "    ax1.tick_params(axis='y')\n",
    "    \n",
    "    for threshold in Post_p:\n",
    "        ax1.axvline(x=threshold, color='orange', linestyle='--', alpha=0.2)\n",
    "        ax1.axhline(y=threshold, color='orange', linestyle='--', alpha=0.2)\n",
    "    \n",
    "    x_vals = np.linspace(0, 1, 100)\n",
    "    ax1.plot(x_vals, x_vals, color='red', linestyle='--', alpha=0.2)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(bin_centers, calibration_prob - test_prob, color='orange', linestyle='-', label='Difference (calibration - test) \\nnormalized % of pathogenic variants', linewidth=3, alpha = 0.7)\n",
    "    ax2.set_ylabel(\"Normalized % of pathogenic variants\", fontsize=12)\n",
    "    y_max = np.nanmax(calibration_prob - test_prob) \n",
    "    ax2.set_yticks(np.arange(0, y_max + 0.1, 0.1))\n",
    "    ax2.tick_params(axis='y')\n",
    "    \n",
    "    ax1.set_xlabel(\"P-KNN Pathogenic Score\", fontsize=12)\n",
    "    ax1.set_xlim([0, 1.0])\n",
    "\n",
    "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "        \n",
    "    all_handles = handles1 + handles2\n",
    "    all_labels = labels1 + labels2\n",
    "    \n",
    "    fig.legend(all_handles, all_labels, loc='lower center', bbox_to_anchor=(0.4, 1.0), frameon=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/gpfs/home/pl2948/VariantInterpretation/KNNCode/{tool}_combined_dualyaxis.svg\", \n",
    "            format=\"svg\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa4fa1-8eb8-4954-a209-9c85d0cbeeff",
   "metadata": {},
   "source": [
    "# Integrating All 13 tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ab142-f35f-4489-996f-5f0f21efce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "select_column = [\n",
    "    'SIFT_score', \n",
    "    'FATHMM_score', \n",
    "    'VEST4_score', \n",
    "    'REVEL_score',\n",
    "    'GERP++_RS', \n",
    "    'phyloP100way_vertebrate', \n",
    "    'EA_1.0',\n",
    "    'BayesDel_nsfp33a_noAF', \n",
    "    'MutPred2.0_score', \n",
    "    'CADDv1.6_PHRED',\n",
    "    'pph2_prob', \n",
    "    'MPC_score', \n",
    "    'PrimateAI_score',\n",
    "    'ClinVar_annotation'\n",
    "]\n",
    "\n",
    "calibration_feature = calibration_data[select_column[:-1]].to_numpy()\n",
    "test_feature = test_data[select_column[:-1]].to_numpy()\n",
    "regularization_feature = gnomAD_set[select_column[:-1]].to_numpy()\n",
    "\n",
    "calibration_label = calibration_data[select_column[-1]].to_numpy()\n",
    "calibration_label_bk = copy.deepcopy(calibration_label)\n",
    "test_label = test_data[select_column[-1]].to_numpy()\n",
    "test_label_bk = copy.deepcopy(test_label)\n",
    "\n",
    "print(calibration_feature.shape, test_feature.shape, regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60b0f6-8dfc-46b8-b885-94174a0d18c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100 \n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512\n",
    "normalization= 'rank'\n",
    "impute = True\n",
    "mi_scaling = True\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "condition_string = 'P-KNN'\n",
    "valid_calibration_idx = ~np.isnan(calibration_feature).all(axis=1) \n",
    "calibration_array = calibration_feature[valid_calibration_idx]\n",
    "calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "valid_test_idx = ~np.isnan(test_feature).all(axis=1) \n",
    "test_array = test_feature[valid_test_idx]\n",
    "test_label = copy.deepcopy(test_label_bk[valid_test_idx])\n",
    "\n",
    "valid_regularization_idx = ~np.isnan(regularization_feature).all(axis=1) \n",
    "regularization_array = regularization_feature[valid_regularization_idx]\n",
    "\n",
    "print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                 calibration_label, Pprior, w_calibration, \n",
    "                                                 n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                 normalization, impute, mi_scaling, n_bootstrap, batch_size)\n",
    "\n",
    "np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_All.npy', test_results_array)\n",
    "\n",
    "test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen13_All.npy')\n",
    "\n",
    "P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "test_data.loc[valid_test_idx, f\"ACMGLLR\"] = ACMG_scores \n",
    "test_data.loc[valid_test_idx, f\"P_KNN_pathogenic\"] = P_KNN_pathogenic \n",
    "\n",
    "evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                  test_label, \n",
    "                                                                                                  p_value, \n",
    "                                                                                                  Pprior, \n",
    "                                                                                                  logbase, \n",
    "                                                                                                  category = condition_string, \n",
    "                                                                                                  show_plot=True, \n",
    "                                                                                                  save_name=\"Clingen13_All\")\n",
    "\n",
    "combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "    \n",
    "print(\"pathogenic evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean():.3f}\")\n",
    "print(\"benign evidence mean\", f\"{evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36536fb9-6b03-4102-b8e0-657945b24419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roc_curves = []\n",
    "\n",
    "for col in select_column[:-1]+[\"ACMGLLR\"]:  # Exclude 'ClinVar_annotation'\n",
    "    roc_curves.append(calculate_roc_and_auc(\n",
    "        test_data['ClinVar_annotation'], test_data[col], col))\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "for fpr, tpr, roc_auc, label in roc_curves:\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Reference diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac487d4-47bc-47d9-92e4-d2d4146889e9",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13974d-d4e5-4ec3-924b-1a6766fe20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "for i in [0, 1]:\n",
    "    print(i)\n",
    "    df = test_data[test_data['ClinVar_annotation']==i][['ACMGLLR', 'ACMGLLR_BayesDel_nsfp33a_noAF']]\n",
    "    display(df)\n",
    "    \n",
    "    p_value_cutoff = 0.05\n",
    "    \n",
    "    side = 'greater' if i == 1 else 'less'\n",
    "\n",
    "    t_stat, p_value = stats.ttest_rel(df['ACMGLLR'], df['ACMGLLR_BayesDel_nsfp33a_noAF'], alternative=side)\n",
    "    \n",
    "    if p_value < p_value_cutoff and t_stat > 0:\n",
    "        result = \"ACMGLLR is significantly higher to ACMGLLR_BayesDel_nsfp33a_noAF\"\n",
    "    elif p_value < p_value_cutoff and t_stat < 0:\n",
    "        result = \"ACMGLLR is significantly lower to ACMGLLR_BayesDel_nsfp33a_noAF\"\n",
    "    else:\n",
    "        result = \"No significant difference between the two groups\"\n",
    "    \n",
    "    print(f\"T-statistic: {t_stat}\")\n",
    "    print(f\"P-value: {np.format_float_scientific(p_value, precision=5)}\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdedc72-ff05-4d8d-ba9d-f699255ffa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "for i in [0, 1]:\n",
    "    print(i)\n",
    "    df = test_data[test_data['ClinVar_annotation']==i][['ACMGLLR', 'ACMGLLR_BayesDel_nsfp33a_noAF']]\n",
    "    display(df)\n",
    "\n",
    "    stat, p_value = stats.wilcoxon(df['ACMGLLR'], df['ACMGLLR_BayesDel_nsfp33a_noAF'])\n",
    "    \n",
    "    print(f\"Wilcoxon Statistic: {stat}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Significant difference between the two tools.\")\n",
    "    else:\n",
    "        print(\"No significant difference between the two tools.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e0f4a-04f4-480d-a20f-fc833bbefc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['P-KNN', \n",
    "                   'BayesDel_nsfp33a_noAF', \n",
    "                   'REVEL_score', \n",
    "                   'MutPred2.0_score',\n",
    "                   'VEST4_score']\n",
    "combine_data = combine_data[combine_data['Category'].isin(columns_to_keep)]\n",
    "combine_data['Category'] = pd.Categorical(combine_data['Category'], categories=columns_to_keep, ordered=True)\n",
    "combine_data = combine_data.sort_values(by='Category')\n",
    "combine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec60594-d16b-4c73-8e1c-75bc5f548a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "ax = sns.violinplot(\n",
    "    x=\"Category\",\n",
    "    y=\"Score\", \n",
    "    hue=\"Label\", \n",
    "    data=combine_data, \n",
    "    split=True, \n",
    "    inner=\"box\", \n",
    "    palette={\"Pathogenic variants\": \"red\", \"Benign variants\": \"blue\"},\n",
    "    alpha=0.6, \n",
    "    density_norm='area'\n",
    ")\n",
    "\n",
    "dark_gray = '0.3'\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"Category\", y=\"Score\", hue=\"Label\", data=combine_data,\n",
    "    showcaps=True,  \n",
    "    showfliers=False,\n",
    "    palette={\"Pathogenic variants\": \"pink\", \"Benign variants\": \"#bae0f5\"},\n",
    "    width=0.1, dodge=True, ax=ax,\n",
    "    whiskerprops={'color': dark_gray, 'linewidth': 1.5, 'zorder': 2},\n",
    "    capprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    medianprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    boxprops={'zorder': 2, 'edgecolor': dark_gray, 'linewidth': 1.5},\n",
    "    hue_order=['Pathogenic variants', 'Benign variants']\n",
    "\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "n_hue = combine_data[\"Label\"].nunique() \n",
    "ax.legend(handles[:n_hue], labels[:n_hue], loc=\"upper right\", fontsize=12)\n",
    "\n",
    "category_labels = [\"P-KNN\", \"BayesDel\", \"REVEL\", \"MutPred2\", \"VEST4\"]\n",
    "plt.xticks(ticks=range(len(category_labels)), labels=category_labels, fontsize=14)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel(\"Evidence strength (LLR)\", fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.savefig(f\"/gpfs/home/pl2948/VariantInterpretation/KNNgraph/{condition_string}_violin.svg\", format=\"svg\")\n",
    "plt.savefig('Fig3A.svg', format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010f249-720e-4da3-b900-a1ad3350310f",
   "metadata": {},
   "source": [
    "# Calibrate VUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2827596-95b4-4e8f-8247-d2b6a7802827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count() \n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\") \n",
    "        print(f\"Memory Usage for GPU {i}:\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated(i) / 1024**2:.2f} MB\") \n",
    "        print(f\"  Cached: {torch.cuda.memory_reserved(i) / 1024**2:.2f} MB\") \n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f4c34-b04b-4b5f-b4f1-b7fa09dddf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30244a31-d0c1-4506-9139-ceb35f5fa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "clinvar_dbNSFP_VUS = pd.read_csv(\"/gpfs/home/pl2948/VariantInterpretation/ClinVarBenchmark/Clinvar_dbNSFP51a_VUS.csv\")\n",
    "\n",
    "clinvar_dbNSFP_VUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650e266-8ac3-487d-9a00-dbb98aa367c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_column_Clingen = [\n",
    "    'SIFT_score', \n",
    "    'FATHMM_score', \n",
    "    'VEST4_score', \n",
    "    'REVEL_score',\n",
    "    'GERP++_RS', \n",
    "    'phyloP100way_vertebrate', \n",
    "    # 'EA_1.0',\n",
    "    'BayesDel_nsfp33a_noAF', \n",
    "    # 'MutPred2.0_score', \n",
    "    'CADDv1.6_PHRED',\n",
    "    'pph2_prob', \n",
    "    'MPC_score', \n",
    "    'PrimateAI_score',\n",
    "    'ClinVar_annotation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633daf0-9793-4422-915c-655537bc94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = clinvar_dbNSFP_VUS.rename(columns={'fathmm-XF_coding_score': 'FATHMM_score',\n",
    "                                               'BayesDel_noAF_score': 'BayesDel_nsfp33a_noAF',\n",
    "                                               'Polyphen2_HVAR_score': 'pph2_prob',\n",
    "                                               'clnsig': 'ClinVar_annotation',\n",
    "                                              })\n",
    "del clinvar_dbNSFP_VUS\n",
    "\n",
    "\n",
    "test_data = test_data[select_column_Clingen[:-1]]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "for col in select_column_Clingen[:-1]:\n",
    "    test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
    "    if col in ['SIFT_score', 'FATHMM_score']:\n",
    "        test_data[col] *=-1\n",
    "\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "display(test_data)\n",
    "print(test_data.isna().sum()/len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5baf1-6106-4ee0-8181-3acdc512b1b9",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b312fa-2eda-4c64-a29b-13e3f5661c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_data[select_column_Clingen[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b5be8-5cd6-463c-b72c-de8da24dcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[select_column_Clingen[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bcf62-d759-4e96-9cab-5b14bb505a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "calibration_feature = calibration_data[select_column_Clingen[:-1]].to_numpy()\n",
    "test_feature = test_data[select_column_Clingen[:-1]].to_numpy()\n",
    "regularization_feature = gnomAD_set[select_column_Clingen[:-1]].to_numpy()\n",
    "\n",
    "calibration_label = calibration_data[select_column_Clingen[-1]].to_numpy()\n",
    "calibration_label_bk = copy.deepcopy(calibration_label)\n",
    "\n",
    "print(calibration_feature.shape, test_feature.shape, regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf5704-f333-4943-a0c7-d62adfa79992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441; # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 4096 # This is for A100, if V100, use 512\n",
    "normalization= 'rank'\n",
    "impute = True\n",
    "mi_scaling = True\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "condition_string = 'P-KNN_VUS'\n",
    "valid_calibration_idx = ~np.isnan(calibration_feature).all(axis=1) \n",
    "calibration_array = calibration_feature[valid_calibration_idx]\n",
    "calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "valid_test_idx = ~np.isnan(test_feature).all(axis=1) \n",
    "test_array = test_feature[valid_test_idx]\n",
    "\n",
    "valid_regularization_idx = ~np.isnan(regularization_feature).all(axis=1) \n",
    "regularization_array = regularization_feature[valid_regularization_idx]\n",
    "\n",
    "print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                 calibration_label, Pprior, w_calibration, \n",
    "                                                 n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                 normalization, impute, mi_scaling, n_bootstrap, batch_size)\n",
    "\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen11_VUS.npy', test_results_array)\n",
    "\n",
    "test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen11_VUS.npy')\n",
    "\n",
    "P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "test_data.loc[valid_test_idx, f\"ACMGLLR\"] = ACMG_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87fe79-5329-46b4-a534-cc93291fcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score_1D, evaluate_result_1D\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441\n",
    "w_calibration=None\n",
    "n_calibration_in_window = 100\n",
    "frac_regularization_in_window=0.03\n",
    "batch_size = 4096 \n",
    "normalization= 'z'\n",
    "impute = False\n",
    "mi_scaling = False\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "i = 6 #BayesDel   \n",
    "condition_string = select_column_Clingen[i]\n",
    "select_feature = i\n",
    "\n",
    "valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "calibration_label = copy.deepcopy(calibration_label_bk[valid_calibration_idx])\n",
    "\n",
    "valid_test_idx = ~np.isnan(test_feature[:,select_feature])\n",
    "test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature])\n",
    "regularization_array = regularization_feature[valid_regularization_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Tool {condition_string}\")\n",
    "print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                 calibration_label, Pprior, w_calibration, \n",
    "                                                 n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                 normalization, impute, mi_scaling, n_bootstrap, batch_size)\n",
    "\n",
    "np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen11_VUS_{condition_string}.npy', test_results_array)\n",
    "\n",
    "test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen11_VUS_{condition_string}.npy')\n",
    "\n",
    "P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score_1D(test_results_array, test_array, p_value, Pprior, logbase)\n",
    "\n",
    "test_data.loc[valid_test_idx, f\"ACMGLLR_{condition_string}\"] = ACMG_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843568a0-49db-49da-8aac-e16a1bb5ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "df = test_data[(test_data['ACMGLLR'].notna())&(test_data['ACMGLLR_BayesDel_nsfp33a_noAF'].notna())][['ACMGLLR', 'ACMGLLR_BayesDel_nsfp33a_noAF']]\n",
    "display(df)\n",
    "\n",
    "p_value_cutoff = 0.05\n",
    "\n",
    "t_stat, p_value = stats.ttest_rel(np.abs(df['ACMGLLR']), np.abs(df['ACMGLLR_BayesDel_nsfp33a_noAF']), alternative='greater')\n",
    "\n",
    "print(f'ACMGLLR mean {np.abs(df[\"ACMGLLR\"]).mean()}')\n",
    "print(f'ACMGLLR_BayesDel_nsfp33a_noAF mean {np.abs(df[\"ACMGLLR_BayesDel_nsfp33a_noAF\"]).mean()}')\n",
    "\n",
    "if p_value < p_value_cutoff and t_stat > 0:\n",
    "    result = \"ACMGLLR is significantly higher to ACMGLLR_BayesDel_nsfp33a_noAF\"\n",
    "elif p_value < p_value_cutoff and t_stat < 0:\n",
    "    result = \"ACMGLLR is significantly lower to ACMGLLR_BayesDel_nsfp33a_noAF\"\n",
    "else:\n",
    "    result = \"No significant difference between the two groups\"\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896844f-6f9d-4967-b944-8aabc3d00f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_results_array = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Clingen11_VUS.npy')\n",
    "\n",
    "logbase = 1124;       # LR+ constant from Tavtigian et al. (changes w/ alpha)\n",
    "Pprior = 0.0441; # Prior probability of pathogenicity (changes w/ c)\n",
    "p_value = 0.05\n",
    "\n",
    "Post_p = np.zeros(4) \n",
    "Post_b = np.zeros(4)\n",
    "\n",
    "for j in range(1, 5):\n",
    "    Post_p[j-1] = logbase ** (1 / 2 ** (j - 1)) * Pprior / ((logbase ** (1 / 2 ** (j - 1)) - 1) * Pprior + 1)\n",
    "    Post_b[j-1] = (logbase ** (1 / 2 ** (j - 1))) * (1 - Pprior) / (((logbase ** (1 / 2 ** (j - 1))) - 1) * (1 - Pprior) + 1)\n",
    "\n",
    "index = int(np.ceil(p_value*test_results_array.shape[1]))\n",
    "P_KNN_pathogenic = np.sort(test_results_array, axis=1)[:, index-1]\n",
    "P_KNN_benign = 1- np.sort(test_results_array, axis=1)[:, -index]\n",
    "\n",
    "P_KNN_evidence_array = np.zeros(len(P_KNN_pathogenic))\n",
    "weights = [8, 4, 2, 1]\n",
    "\n",
    "print(\"Pathogenic evidence\")\n",
    "proportion_old = 0\n",
    "for i, threshold in enumerate(Post_p):\n",
    "    pathogenic_count = (P_KNN_pathogenic > threshold).sum()\n",
    "    proportion = pathogenic_count / len(P_KNN_pathogenic)\n",
    "    print(f\"Threshold {threshold:.3f}: {pathogenic_count} ({proportion:.2%}) pathogenic variants\", f\"{(proportion-proportion_old):.2%}\")\n",
    "    proportion_old = proportion\n",
    "    P_KNN_evidence_array[(P_KNN_pathogenic > threshold) & (P_KNN_evidence_array == 0)] = weights[i]\n",
    "    \n",
    "print(\"Benign evidence\")\n",
    "proportion_old = 0\n",
    "for i, threshold in enumerate(Post_b):\n",
    "    benign_count = (P_KNN_benign > threshold).sum()\n",
    "    proportion = benign_count / len(P_KNN_benign)\n",
    "    print(f\"Threshold {threshold:.3f}: {benign_count} ({proportion:.2%}) benign variants\", f\"{(proportion-proportion_old):.2%}\")\n",
    "    proportion_old = proportion\n",
    "    P_KNN_evidence_array[(P_KNN_benign > threshold) & (P_KNN_evidence_array == 0)] = weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e76cb3-4518-4b27-bceb-98bbdaa6f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pathogenic_threshold_dict = {'REVEL_score': [np.inf, 0.932, 0.773, 0.644],\n",
    "                             'VEST4_score': [np.inf, 0.965, 0.861, 0.764],\n",
    "                             'BayesDel_nsfp33a_noAF': [np.inf, 0.5, 0.27, 0.13]\n",
    "                            }\n",
    "\n",
    "benign_threshold_dict = {'REVEL_score': [0.003, 0.016, 0.183, 0.290],\n",
    "                         'VEST4_score': [-np.inf, -np.inf, 0.302, 0.449],\n",
    "                         'BayesDel_nsfp33a_noAF': [-np.inf, -np.inf, -0.36, -0.18]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760c9e3-76f1-4c2a-a40f-2bf9d987a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleTool_evidence_array = np.zeros((len(test_data), 3))\n",
    "weights = [8, 4, 2, 1]\n",
    "\n",
    "for p, tool in enumerate(['REVEL_score', 'VEST4_score', 'BayesDel_nsfp33a_noAF']):\n",
    "    Post_p = pathogenic_threshold_dict[tool]\n",
    "    Post_b = benign_threshold_dict[tool]\n",
    "    score = test_data[tool]\n",
    "    print(tool)\n",
    "    print(\"Pathogenic evidence\")\n",
    "    proportion_old = 0\n",
    "    \n",
    "    for i, threshold in enumerate(Post_p):\n",
    "        pathogenic_count = (score >= threshold).sum()\n",
    "        proportion = pathogenic_count / len(score)\n",
    "        print(f\"Threshold {threshold:.3f}: {pathogenic_count} ({proportion:.2%}) pathogenic variants\", f\"{(proportion-proportion_old):.2%}\")\n",
    "        proportion_old = proportion\n",
    "        SingleTool_evidence_array[(score >= threshold) & (SingleTool_evidence_array[:,p]==0), p]=weights[i]\n",
    "    print(\"Benign evidence\")\n",
    "    \n",
    "    proportion_old = 0\n",
    "    for i, threshold in enumerate(Post_b):\n",
    "        benign_count = (score < threshold).sum()\n",
    "        proportion = benign_count / len(score)\n",
    "        print(f\"Threshold {threshold:.3f}: {benign_count} ({proportion:.2%}) benign variants\", f\"{(proportion-proportion_old):.2%}\")\n",
    "        proportion_old = proportion\n",
    "        SingleTool_evidence_array[(score < threshold) & (SingleTool_evidence_array[:,p]==0), p]=weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f12062-1dc2-41ae-ba37-001d8c8baaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stat, p_value = stats.wilcoxon(np.abs(P_KNN_evidence_array), np.abs(SingleTool_evidence_array[:,0]))\n",
    "\n",
    "print(f\"Wilcoxon Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Significant difference between the two tools.\")\n",
    "else:\n",
    "    print(\"No significant difference between the two tools.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd7e5a-f0f9-4f9b-859d-8040946797f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "median_A = np.median(np.abs(P_KNN_evidence_array))\n",
    "median_B = np.median(np.abs(SingleTool_evidence_array[:,2]))\n",
    "\n",
    "print(f\"Median of P_KNN evidence: {median_A:.3f}\")\n",
    "print(f\"Median of SingleTool evidence: {median_B:.3f}\")\n",
    "\n",
    "if median_A > median_B:\n",
    "    print(\"P_KNN_evidence_array is generally stronger.\")\n",
    "elif median_A < median_B:\n",
    "    print(\"SingleTool_evidence_array is generally stronger.\")\n",
    "else:\n",
    "    print(\"Both tools have similar evidence assignment strength.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

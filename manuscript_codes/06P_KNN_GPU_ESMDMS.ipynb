{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5f3dc7-0d96-4bd8-9468-fd4a239c6a57",
   "metadata": {},
   "source": [
    "# TP53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34528f-7e74-4594-a4a5-a13ca7b058ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TP53_ClinVar = pd.read_csv(\"/gpfs/home/pl2948/VariantInterpretation/Data/TP53_ESM_DMS.csv\")\n",
    "TP53_ClinVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f24518-7d7b-404a-86c0-4c5fac09dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_column = ['ESM1b_score',\n",
    "                  'TP53_transcription_urn_mavedb_00001234-0-1_scores',\n",
    "                  'TP53_DNE_urn_mavedb_00001235-a-1_scores',\n",
    "                  'urn_mavedb_00000068-b-1_scores',\n",
    "                  'urn_mavedb_00001234-g-1_scores',\n",
    "                  'urn_mavedb_00001234-e-1_scores', \n",
    "                  'urn_mavedb_00001234-d-1_scores',\n",
    "                  'urn_mavedb_00001213-a-1_scores',\n",
    "                  'urn_mavedb_00001236-0-1_scores', \n",
    "                  'urn_mavedb_00001234-h-1_scores',\n",
    "                  'urn_mavedb_00000068-c-1_scores', \n",
    "                  'urn_mavedb_00001234-a-1_scores',\n",
    "                  'urn_mavedb_00001234-c-1_scores', \n",
    "                  'urn_mavedb_00001234-b-1_scores',\n",
    "                  'urn_mavedb_00001234-f-1_scores', \n",
    "                  'urn_mavedb_00000068-0-1_scores',\n",
    "                  'urn_mavedb_00000068-a-1_scores']\n",
    "\n",
    "feature = TP53_ClinVar[feature_column].to_numpy().astype(float)\n",
    "print(feature.shape)\n",
    "\n",
    "label = TP53_ClinVar['ClinVar_annotation'].to_numpy().astype(int)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda311e-795a-41e4-9201-af59d6e7fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP53_ClinVar[feature_column].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad77a35-ffea-4a50-8210-59a5373e5449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tool exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab47c20-6a81-4957-a7df-88a723d5af3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = np.abs(TP53_ClinVar[feature_column].corr(method='pearson'))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True,\n",
    "            cbar_kws={\"shrink\": .75}, linewidths=0.5, linecolor='white')\n",
    "plt.title(\"Pearson Correlation Heatmap between MAVEs Scores\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110558fd-d905-47c7-af1c-1e1a332b6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def conditional_mutual_info(feature_1, feature_2, label):\n",
    "    feature_1, feature_2 = feature_1.reshape(-1, 1), feature_2.reshape(-1, 1)\n",
    "    \n",
    "    feature_1_0, feature_2_0 = feature_1[label == 0], feature_2[label == 0]\n",
    "    feature_1_1, feature_2_1 = feature_1[label == 1], feature_2[label == 1]\n",
    "\n",
    "    if len(feature_1_0) > 1 and len(feature_2_0) > 1:\n",
    "        mi_0 = mutual_info_regression(feature_1_0, feature_2_0.ravel(), random_state=0)[0]\n",
    "    else:\n",
    "        mi_0 = 0  \n",
    "\n",
    "    if len(feature_1_1) > 1 and len(feature_2_1) > 1:\n",
    "        mi_1 = mutual_info_regression(feature_1_1, feature_2_1.ravel(), random_state=0)[0]\n",
    "    else:\n",
    "        mi_1 = 0 \n",
    "\n",
    "    p0, p1 = np.mean(label == 0), np.mean(label == 1)\n",
    "    conditional_mi = p0 * mi_0 + p1 * mi_1\n",
    "\n",
    "    return conditional_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30366254-9214-43ea-835a-ff5ebb952a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def permutation_pvalue_cmi(feature_1, feature_2, label, n_perm=10000, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    I_obs = conditional_mutual_info(feature_1, feature_2, label)\n",
    "\n",
    "    unique_labels = np.unique(label)\n",
    "    group_indices = {lv: np.where(label == lv)[0] for lv in unique_labels}\n",
    "\n",
    "    exceed = 0\n",
    "    for _ in range(n_perm):\n",
    "        feature_2_perm = np.array(feature_2, copy=True)\n",
    "        # re assign feature_2\n",
    "        for idx in group_indices.values():\n",
    "            feature_2_perm[idx] = feature_2_perm[idx][rng.permutation(len(idx))]\n",
    "        I_perm = conditional_mutual_info(feature_1, feature_2_perm, label)\n",
    "        if I_perm >= I_obs - 1e-12:\n",
    "            exceed += 1\n",
    "\n",
    "    p_val = (exceed + 1) / (n_perm + 1)\n",
    "    return I_obs, p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b38830-292f-4ccf-858e-6336649f4eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from P_KNN_GPU import silhouette_score_1d_torch\n",
    "\n",
    "for i in range(1,len(feature_column)):\n",
    "    valid_label = label[~np.isnan(feature[:,i])].ravel()\n",
    "    valid_feature = feature[~np.isnan(feature[:,i]), i]\n",
    "    ESM = feature[~np.isnan(feature[:,i]), 0]\n",
    "    \n",
    "    roc_auc = roc_auc_score(valid_label, valid_feature)\n",
    "    if roc_auc < 0.5: roc_auc = 1-roc_auc\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    mutual_information = mutual_info_classif(valid_feature.reshape(-1, 1), valid_label)\n",
    "    print(f\"Mutual Information: {mutual_information[0]:.4f}\")\n",
    "\n",
    "    silhouette_score= silhouette_score_1d_torch(torch.tensor(valid_feature).reshape(-1, 1), torch.tensor(valid_label))\n",
    "    print(f\"Silhouette score: {silhouette_score:.4f}\")\n",
    "\n",
    "    # conditional_mi = conditional_mutual_info(ESM, valid_feature, valid_label)\n",
    "    \n",
    "    conditional_mi, p_val = permutation_pvalue_cmi(ESM, valid_feature, valid_label, n_perm=1000, random_state=0)\n",
    "    print(f\"Conditional Mutual Information: {conditional_mi:.4f}, p={p_val:.4f}\")\n",
    "\n",
    "    rank_valid_feature = np.argsort(np.argsort(valid_feature))\n",
    "    rank_ESM = np.argsort(np.argsort(ESM))\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    plt.hist(feature[label == 0, i], color='blue', alpha=0.7, label=\"Benign\")\n",
    "    plt.hist(feature[label == 1, i], color='red', alpha=0.7, label=\"Pathogenic\")\n",
    "    \n",
    "    plt.xlabel(\"ESM1b\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(feature_column[i])\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"Fig6BESM1b.svg\", format=\"svg\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "    \n",
    "    fig.suptitle(feature_column[i])\n",
    "    \n",
    "    axs[0].scatter(valid_feature[valid_label==0], ESM[valid_label==0], color='blue', alpha=0.7, label='Benign')\n",
    "    axs[0].scatter(valid_feature[valid_label==1], ESM[valid_label==1], color='red', alpha=0.7, label='Pathogenic')\n",
    "    axs[0].set_xlabel(\"MAVE score\", fontsize=12)\n",
    "    axs[0].set_ylabel(\"ESM1b Score\", fontsize=12)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].scatter(rank_valid_feature[valid_label==0], rank_ESM[valid_label==0], color='blue', alpha=0.7)\n",
    "    axs[1].scatter(rank_valid_feature[valid_label==1], rank_ESM[valid_label==1], color='red', alpha=0.7)\n",
    "    axs[1].set_xlabel(\"MAVE rank score\", fontsize=12)\n",
    "    axs[1].set_ylabel(\"ESM1b rank Score\", fontsize=12)\n",
    "    \n",
    "    # plt.savefig(\"Fig6_combined.svg\", format=\"svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a43ea-866c-44de-980a-7de3a8a5fee7",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7643f-6b47-4f1d-9102-b5ea66e34e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_column = ['ESM1b_score',\n",
    "                  'TP53_transcription_urn_mavedb_00001234-0-1_scores',\n",
    "                  'TP53_DNE_urn_mavedb_00001235-a-1_scores',\n",
    "                  'urn_mavedb_00000068-b-1_scores',\n",
    "                  'urn_mavedb_00001234-g-1_scores',\n",
    "                  'urn_mavedb_00001234-e-1_scores', \n",
    "                  'urn_mavedb_00001234-d-1_scores',\n",
    "                  'urn_mavedb_00001213-a-1_scores',\n",
    "                  'urn_mavedb_00001236-0-1_scores', \n",
    "                  'urn_mavedb_00001234-h-1_scores',\n",
    "                  'urn_mavedb_00000068-c-1_scores', \n",
    "                  'urn_mavedb_00001234-a-1_scores',\n",
    "                  'urn_mavedb_00001234-c-1_scores', \n",
    "                  'urn_mavedb_00001234-b-1_scores',\n",
    "                  'urn_mavedb_00001234-f-1_scores', \n",
    "                  'urn_mavedb_00000068-0-1_scores',\n",
    "                  'urn_mavedb_00000068-a-1_scores']\n",
    "\n",
    "feature = TP53_ClinVar[feature_column].to_numpy().astype(float)\n",
    "print(feature.shape)\n",
    "\n",
    "label = TP53_ClinVar['ClinVar_annotation'].to_numpy().astype(int)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0531a39-38ba-4dbe-b568-3639cf1712cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pprior = 0.22 # Prior probability of pathogenicity (changes w/ c)\n",
    "n_calibration_in_window = 10;   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window=0.03\n",
    "w_calibration=None\n",
    "batch_size=512\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98c6c3-3f15-4467-8f97-5007f0ce420c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu\n",
    "import gc\n",
    "\n",
    "for tool in range(len(feature_column)):\n",
    "    print(f\"MAVE: {feature_column[tool]}\")\n",
    "    valid_label = label[~np.isnan(feature[:,tool])]\n",
    "    valid_feature = feature[~np.isnan(feature[:,tool]), tool]\n",
    "    \n",
    "    test_results_array = np.zeros((len(valid_feature), n_bootstrap))\n",
    "\n",
    "    normalization='z'\n",
    "    impute=False\n",
    "    mi_scaling=False\n",
    "    \n",
    "    for i in range(len(valid_feature)):\n",
    "        test_feature = valid_feature[i].reshape(-1, 1)\n",
    "        test_label = np.array([valid_label[i]])\n",
    "    \n",
    "        feature_c = np.delete(valid_feature, i, axis=0).reshape(-1, 1)\n",
    "        label_c = np.delete(valid_label, i, axis=0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        test_results = get_bootstrap_KNN_score_gpu(feature_c, test_feature, feature_c, \n",
    "                                                   label_c, Pprior, w_calibration, \n",
    "                                                   n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                   normalization, \n",
    "                                                   impute, \n",
    "                                                   mi_scaling, \n",
    "                                                   n_bootstrap, batch_size)\n",
    "    \n",
    "        test_results_array[i, :] = test_results\n",
    "\n",
    "    np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/KNN_MAVE_{feature_column[tool]}.npy', test_results_array)\n",
    "    print('Single Tool calibration completed')\n",
    "\n",
    "    if tool == 0: continue\n",
    "    \n",
    "    ESM_feature = feature[:, [0, tool]] \n",
    "    test_results_array = np.zeros((len(ESM_feature), n_bootstrap))\n",
    "\n",
    "    normalization='rank' \n",
    "    impute=True\n",
    "    mi_scaling=True\n",
    "\n",
    "    for i in range(len(ESM_feature)):\n",
    "        test_feature = ESM_feature[i].reshape(1, -1)\n",
    "        test_label = np.array([label[i]]) \n",
    "        \n",
    "        feature_c = np.delete(ESM_feature, i, axis=0)\n",
    "        label_c = np.delete(label, i, axis=0)\n",
    "    \n",
    "        test_results = get_bootstrap_KNN_score_gpu(feature_c, test_feature, feature_c, \n",
    "                                                   label_c, Pprior, w_calibration, \n",
    "                                                   n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                   normalization, \n",
    "                                                   impute, \n",
    "                                                   mi_scaling, \n",
    "                                                   n_bootstrap, batch_size)\n",
    "\n",
    "        test_results_array[i, :] = test_results\n",
    "\n",
    "    np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/KNN_ESMMAVE_{feature_column[tool]}.npy', test_results_array)\n",
    "    print(\"P-KNN completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61117bd-6916-4182-9bf4-df913cc69cf9",
   "metadata": {},
   "source": [
    "## Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89e98f-e405-46cd-bca5-add294d57966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_column = ['ESM1b_score',\n",
    "                  'TP53_transcription_urn_mavedb_00001234-0-1_scores',\n",
    "                  'TP53_DNE_urn_mavedb_00001235-a-1_scores',\n",
    "                  'urn_mavedb_00000068-b-1_scores',\n",
    "                  'urn_mavedb_00001234-g-1_scores',\n",
    "                  'urn_mavedb_00001234-e-1_scores', \n",
    "                  'urn_mavedb_00001234-d-1_scores',\n",
    "                  'urn_mavedb_00001213-a-1_scores',\n",
    "                  'urn_mavedb_00001236-0-1_scores', \n",
    "                  'urn_mavedb_00001234-h-1_scores',\n",
    "                  'urn_mavedb_00000068-c-1_scores', \n",
    "                  'urn_mavedb_00001234-a-1_scores',\n",
    "                  'urn_mavedb_00001234-c-1_scores', \n",
    "                  'urn_mavedb_00001234-b-1_scores',\n",
    "                  'urn_mavedb_00001234-f-1_scores', \n",
    "                  'urn_mavedb_00000068-0-1_scores',\n",
    "                  'urn_mavedb_00000068-a-1_scores']\n",
    "\n",
    "feature = TP53_ClinVar[feature_column].to_numpy().astype(float)\n",
    "print(feature.shape)\n",
    "\n",
    "label = TP53_ClinVar['ClinVar_annotation'].to_numpy().astype(int)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d0a04-db57-481c-9ac1-f12592d55431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from P_KNN_GPU import get_P_KNN_ACMG_score_1D, get_P_KNN_ACMG_score, evaluate_result_1D, evaluate_result, silhouette_score_1d_torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "p_value = 0.05\n",
    "Pprior = 0.22\n",
    "logbase = 1730\n",
    "\n",
    "combine_data = pd.DataFrame([])\n",
    "silhouette_score_dict = {}\n",
    "roc_auc_dict = {}\n",
    "LLR_single_tool_dict = {}\n",
    "LLR_P_KNN_dict = {}\n",
    "\n",
    "for tool in range(len(feature_column)):\n",
    "    print(f\"MAVE: {feature_column[tool]}\")\n",
    "    valid_label = label[~np.isnan(feature[:,tool])]\n",
    "    valid_feature = feature[~np.isnan(feature[:,tool]), tool]\n",
    "\n",
    "    silhouette_score= silhouette_score_1d_torch(torch.tensor(valid_feature).reshape(-1, 1), torch.tensor(valid_label))\n",
    "    print(f\"Silhouette score: {silhouette_score:.4f}\")\n",
    "    silhouette_score_dict[feature_column[tool]] = silhouette_score\n",
    "    \n",
    "    roc_auc = roc_auc_score(valid_label, valid_feature)\n",
    "    if roc_auc < 0.5: \n",
    "        valid_feature*=-1\n",
    "        roc_auc = 1-roc_auc\n",
    "        \n",
    "    roc_auc_dict[feature_column[tool]] = roc_auc\n",
    "    \n",
    "    print(\"Single-tool\")\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/KNN_MAVE_{feature_column[tool]}.npy')\n",
    "\n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result_1D(test_results_array,\n",
    "                                                                                                  valid_feature,\n",
    "                                                                                                  valid_label, \n",
    "                                                                                                  p_value, \n",
    "                                                                                                  Pprior, \n",
    "                                                                                                  logbase, \n",
    "                                                                                                  category = feature_column[tool], \n",
    "                                                                                                  show_plot=True, \n",
    "                                                                                                  save_name=None)\n",
    "    \n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score_1D(test_results_array, valid_feature, p_value, Pprior, logbase)\n",
    "\n",
    "    TP53_ClinVar.loc[TP53_ClinVar[feature_column[tool]].notna(), f\"ACMGLLR_{feature_column[tool]}\"] = ACMG_scores\n",
    "    \n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)  \n",
    "    \n",
    "    LLR_mean_pathogenic = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "    LLR_mean_benign = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "\n",
    "    LLR_single_tool_dict[feature_column[tool]] = (LLR_mean_pathogenic + LLR_mean_benign)/2\n",
    "    \n",
    "    print(\"pathogenic evidence mean\", f\"{LLR_mean_pathogenic:.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{LLR_mean_benign:.3f}\")\n",
    "\n",
    "    if tool==0: continue\n",
    "\n",
    "    print(\"P-KNN\")\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/KNN_ESMMAVE_{feature_column[tool]}.npy')\n",
    "    ESM_feature = feature[:, [0, tool]] \n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array, \n",
    "                                                                                               label, \n",
    "                                                                                               p_value, \n",
    "                                                                                               Pprior, \n",
    "                                                                                               logbase, \n",
    "                                                                                               category = f\"ESM1b_{feature_column[tool]}\", \n",
    "                                                                                               show_plot=True, \n",
    "                                                                                               save_name=tool)\n",
    "\n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True) \n",
    "    \n",
    "    LLR_mean_pathogenic = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "    LLR_mean_benign = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "\n",
    "    LLR_P_KNN_dict[feature_column[tool]] = (LLR_mean_pathogenic + LLR_mean_benign)/2\n",
    "    \n",
    "    print(\"pathogenic evidence mean\", f\"{LLR_mean_pathogenic:.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{LLR_mean_benign:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fd9fa-9526-4dd2-805c-ea33090c7548",
   "metadata": {},
   "source": [
    "# Final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd6a29-db75-44f2-8a41-ac5620d1aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLR_single_tool_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9582476-f2ba-460e-aaeb-d179d8d8825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "keys = list(LLR_single_tool_dict.keys())\n",
    "keys.remove('ESM1b_score')\n",
    "x1 = np.array([LLR_single_tool_dict[k] for k in keys])\n",
    "y1 = np.array([LLR_P_KNN_dict[k] for k in keys])\n",
    "color1 = np.array([silhouette_score_dict[k] for k in keys])\n",
    "x2 = color1\n",
    "y2 = y1 / x1\n",
    "x3 = np.array([roc_auc_dict[k] for k in keys])\n",
    "y3 = y1 / x1\n",
    "\n",
    "plt.figure(figsize=(4.7, 6))\n",
    "scatter1 = plt.scatter(x1, y1, c=color1, cmap='viridis', edgecolor='k')\n",
    "plt.xlabel('Mean evidence strength (Single Tool)')\n",
    "plt.ylabel('Mean evidence strength (P-KNN)')\n",
    "min_val = min(min(x1), min(y1))\n",
    "max_val = max(max(x1), max(y1))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], linestyle='--', color='gray', label='y = x')\n",
    "# plt.legend()\n",
    "cbar = plt.colorbar(scatter1, orientation='horizontal', pad=0.15)\n",
    "cbar.set_label('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig6E.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x2, y2, c='dodgerblue', edgecolor='k')\n",
    "plt.axhline(1, color='gray', linestyle='--')\n",
    "plt.xlabel('Silhouette Score')\n",
    "plt.ylabel('Mean evidence strength ratio')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig6F.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x3, y3, c='salmon', edgecolor='k')\n",
    "plt.axhline(1, color='gray', linestyle='--')\n",
    "plt.xlabel('ROC AUC (Single Tool)')\n",
    "plt.ylabel('Mean evidence strength ratio (P-KNN / Single)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04996cc-f3a0-4044-8828-8320107d7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_result(test_results_array, test_label, p_value, Pprior, logbase=None, category = None, show_plot=True, save_name=None):\n",
    "    if logbase is None:\n",
    "        logbase = get_logbase(Pprior)\n",
    "    \n",
    "    w_test = (1 - Pprior) * sum(test_label == 1) / (sum(test_label == 0) * Pprior)  \n",
    "    \n",
    "    # Calculate the pathogenic and benign threshold for evidence level\n",
    "    Post_p = np.zeros(4) \n",
    "    Post_b = np.zeros(4)\n",
    "\n",
    "    for j in range(4):\n",
    "        Post_p[j] = logbase ** (1 / 2 ** j) * Pprior / ((logbase ** (1 / 2 ** j) - 1) * Pprior + 1)\n",
    "        Post_b[j] = (logbase ** (1 / 2 ** j)) * (1 - Pprior) / (((logbase ** (1 / 2 ** j)) - 1) * (1 - Pprior) + 1)\n",
    "\n",
    "    Pathogenic_test_results_array = test_results_array[test_label == 1]\n",
    "    Benign_test_results_array = test_results_array[test_label == 0]\n",
    "\n",
    "    Pathogenic_P_KNN_pathogenic, Pathogenic_P_KNN_benign, Pathogenic_ACMG_scores = get_P_KNN_ACMG_score(\n",
    "        Pathogenic_test_results_array, p_value, Pprior, logbase)\n",
    "    \n",
    "    Benign_P_KNN_pathogenic, Benign_P_KNN_benign, Benign_ACMG_scores = get_P_KNN_ACMG_score(\n",
    "        Benign_test_results_array, p_value, Pprior, logbase) \n",
    "    \n",
    "    # Print correct and incorrect assignment of pathogenic and benign variants\n",
    "    print(\"Pathogenic evidence\")\n",
    "    accumulate_pathogenic_count = 0\n",
    "    accumulate_benign_count = 0\n",
    "    for ACMGevidence, threshold in zip([\"+8\", \"+4\", \"+2\", \"+1\"], Post_p):\n",
    "        pathogenic_count = (Pathogenic_P_KNN_pathogenic > threshold).sum() - accumulate_pathogenic_count\n",
    "        benign_count = (Benign_P_KNN_pathogenic > threshold).sum() - accumulate_benign_count\n",
    "        accumulate_pathogenic_count += pathogenic_count\n",
    "        accumulate_benign_count += benign_count\n",
    "        print(f\"  Evidence score {ACMGevidence} Probability threshold {threshold:.3f}:\")\n",
    "        print(f\"    Pathogenic {pathogenic_count} ({pathogenic_count/(len(Pathogenic_P_KNN_pathogenic)):.2%}) pathogenic variants\")\n",
    "        print(f\"    Benign {benign_count} ({benign_count/(len(Benign_P_KNN_pathogenic)):.2%}) error benign variants\")\n",
    "        print(f\"    Weighted correct rate: {pathogenic_count/(pathogenic_count+benign_count*w_test):.2%}\")\n",
    "\n",
    "    print(\"Benign evidence\")\n",
    "    accumulate_pathogenic_count = 0\n",
    "    accumulate_benign_count = 0\n",
    "    for ACMGevidence, threshold in zip([\"+8\", \"+4\", \"+2\", \"+1\"], Post_b):\n",
    "        pathogenic_count = (Pathogenic_P_KNN_benign > threshold).sum() - accumulate_pathogenic_count\n",
    "        benign_count = (Benign_P_KNN_benign > threshold).sum() - accumulate_benign_count\n",
    "        accumulate_pathogenic_count += pathogenic_count\n",
    "        accumulate_benign_count += benign_count\n",
    "        print(f\"  Evidence score {ACMGevidence} Probability threshold {threshold:.3f}:\")\n",
    "        print(f\"    Benign {benign_count} ({benign_count/(len(Benign_P_KNN_benign)):.2%}) benign variants\")\n",
    "        print(f\"    Pathogenic {pathogenic_count} ({pathogenic_count/(len(Pathogenic_P_KNN_benign)):.2%}) error pathogenic variants\")\n",
    "        print(f\"    Weighted correct rate: {benign_count*w_test/(pathogenic_count+benign_count*w_test):.2%}\")\n",
    "\n",
    "    # Evidence violin plot\n",
    "    evidence_strength_data = pd.DataFrame({\n",
    "        \"Score\": np.concatenate([-Benign_ACMG_scores, Pathogenic_ACMG_scores]),\n",
    "        \"Label\": [\"Benign\"] * len(Benign_ACMG_scores) + [\"Pathogenic\"] * len(Pathogenic_ACMG_scores),\n",
    "        \"Category\": [category] * (len(Benign_ACMG_scores) + len(Pathogenic_ACMG_scores))\n",
    "        })\n",
    "\n",
    "    if show_plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        sns.set(style=\"ticks\")\n",
    "    \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.violinplot(\n",
    "            x=\"Category\",\n",
    "            y=\"Score\", \n",
    "            hue=\"Label\",   # Pathogenic and Benign \n",
    "            data=evidence_strength_data, \n",
    "            split=True,   # on each side of violin\n",
    "            inner=\"quart\", \n",
    "            palette={\"Pathogenic\": \"red\", \"Benign\": \"blue\"},\n",
    "            alpha=0.6, \n",
    "            density_norm='area'\n",
    "        )\n",
    "        \n",
    "        plt.xlabel(\"\")\n",
    "        plt.ylabel(\"Evidence Score (log likelihood)\", fontsize=14)\n",
    "        plt.legend(loc='upper right')\n",
    "        sns.despine(top=True, right=True)\n",
    "        \n",
    "        if save_name:\n",
    "            plt.savefig(f\"{save_name}_ACMGevidence.svg\", format=\"svg\")\n",
    "        plt.show()\n",
    "\n",
    "    # Pathogenic Calibration Plot with Confidence Interval\n",
    "    num_bins = 10\n",
    "    bins = np.linspace(0, 1, num_bins + 1)\n",
    "    \n",
    "    pathogenic_counts, _ = np.histogram(Pathogenic_P_KNN_pathogenic, bins=bins)\n",
    "    benign_counts, _ = np.histogram(Benign_P_KNN_pathogenic, bins=bins)\n",
    "\n",
    "    pathogenic_ratios, ci_lower, ci_upper = weighted_score_with_binom_ci(pathogenic_counts, benign_counts, w_test, p_value)\n",
    "\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    valid_mask = ~np.isnan(pathogenic_ratios) & ~np.isnan(ci_lower) & ~np.isnan(ci_upper)\n",
    "\n",
    "    pathogenic_calibration_dict = {}\n",
    "\n",
    "    pathogenic_calibration_dict['bin_centers'] = bin_centers[valid_mask]\n",
    "    pathogenic_calibration_dict['ratios'] = pathogenic_ratios[valid_mask]\n",
    "    pathogenic_calibration_dict['ci_lower'] = ci_lower[valid_mask]\n",
    "    pathogenic_calibration_dict['ci_upper'] = ci_upper[valid_mask]\n",
    "\n",
    "\n",
    "    bins = np.linspace(0.95, 1, num_bins + 1)\n",
    "\n",
    "    pathogenic_counts, _ = np.histogram(Pathogenic_P_KNN_benign, bins=bins)\n",
    "    benign_counts, _ = np.histogram(Benign_P_KNN_benign, bins=bins)\n",
    "    \n",
    "    benign_ratios, ci_lower, ci_upper = weighted_score_with_binom_ci(benign_counts, pathogenic_counts, 1/w_test, p_value)\n",
    "\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    valid_mask = ~np.isnan(benign_ratios) & ~np.isnan(ci_lower) & ~np.isnan(ci_upper)\n",
    "\n",
    "    benign_calibration_dict = {}\n",
    "    benign_calibration_dict['bin_centers'] = bin_centers[valid_mask]\n",
    "    benign_calibration_dict['ratios'] = benign_ratios[valid_mask]\n",
    "    benign_calibration_dict['ci_lower'] = ci_lower[valid_mask]\n",
    "    benign_calibration_dict['ci_upper'] = ci_upper[valid_mask]\n",
    "\n",
    "    if show_plot:\n",
    "        # Plot the calibration curve for pathogenic\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(pathogenic_calibration_dict['bin_centers'], pathogenic_calibration_dict['ratios'], \n",
    "                 'o-', color='red', label='Pathogenic Probability')\n",
    "        plt.fill_between(pathogenic_calibration_dict['bin_centers'], \n",
    "                         pathogenic_calibration_dict['ci_lower'], pathogenic_calibration_dict['ci_upper'], \n",
    "                         color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "        plt.xlabel(\"P-KNN Pathogenic Score\", fontsize=14)\n",
    "        plt.ylabel(\"Pathogenic Probability\", fontsize=14)\n",
    "        plt.legend(loc='lower right')\n",
    "        \n",
    "        x_vals = np.linspace(0, 1, 100)\n",
    "        plt.plot(x_vals, x_vals, label=\"y = x\", color='red', linestyle='--', alpha=0.2)\n",
    "        \n",
    "        for threshold in Post_p:\n",
    "            plt.axvline(x=threshold, color='orange', linestyle='--', label=f'X = {threshold}', alpha=0.2)\n",
    "            plt.axhline(y=threshold, color='orange', linestyle='--', label=f'Y = {threshold}', alpha=0.2)\n",
    "\n",
    "        sns.despine(top=True, right=True)   \n",
    "        if save_name:\n",
    "            plt.savefig(f\"{save_name}_P_Calibration.svg\", format=\"svg\")        \n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # Plot the calibration curve for benign\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.plot(benign_calibration_dict['bin_centers'], benign_calibration_dict['ratios'],\n",
    "                 'o-', color='blue', label='Benign Probability')\n",
    "        plt.fill_between(benign_calibration_dict['bin_centers'],\n",
    "                         benign_calibration_dict['ci_lower'], benign_calibration_dict['ci_upper'],\n",
    "                        color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "        plt.xlabel(\"P-KNN Benign Score\", fontsize=14)\n",
    "        plt.ylabel(\"Benign Probability\", fontsize=14)\n",
    "        plt.ylim(0.95, 1)\n",
    "        plt.xlim(0.95, 1)\n",
    "        plt.legend(loc='lower right')\n",
    "        \n",
    "        x_vals = np.linspace(0.95, 1, 100)\n",
    "        plt.plot(x_vals, x_vals, label=\"y = x\", color='blue', linestyle='--', alpha=0.2)\n",
    "        \n",
    "        for threshold in Post_b:\n",
    "            plt.axvline(x=threshold, color='cyan', linestyle='--', label=f'X = {threshold}', alpha=0.2)\n",
    "            plt.axhline(y=threshold, color='cyan', linestyle='--', label=f'Y = {threshold}', alpha=0.2)\n",
    "\n",
    "        sns.despine(top=True, right=True)\n",
    "        if save_name:\n",
    "            plt.savefig(f\"{save_name}_B_Calibration.svg\", format=\"svg\")  \n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    return evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d484f-99b9-4f6c-8744-75a0124ea88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase=None):\n",
    "    \"\"\"\n",
    "    Calculate the ACMG scores for pathogenicity and benignity based on P-KNN probabilities.\n",
    "    This function computes the P-KNN pathogenic and benign probabilities, converts them\n",
    "    to ACMG scores, and adjusts the scores to be within the range [0, 8]. The final ACMG\n",
    "    scores are calculated as the difference between the pathogenic and benign scores.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    test_results_array : numpy.ndarray\n",
    "        A 2D array where each row represents the test results for a sample, and each column\n",
    "        represents a probability value.\n",
    "    p_value : float\n",
    "        The p-value used to determine the index for selecting probabilities. Should be in\n",
    "        the range (0, 1].\n",
    "    Pprior : float\n",
    "        The prior probability of pathogenicity.\n",
    "    logbase : float, optional\n",
    "        The logarithmic base used for converting probabilities to ACMG scores. If not\n",
    "        provided, it will be calculated using the `get_logbase` function.\n",
    "    Returns:\n",
    "    --------\n",
    "    P_KNN_pathogenic : numpy.ndarray\n",
    "        A 1D array containing the P-KNN pathogenic probabilities for each sample.\n",
    "    P_KNN_benign : numpy.ndarray\n",
    "        A 1D array containing the P-KNN benign probabilities for each sample.\n",
    "    ACMG_scores : numpy.ndarray\n",
    "        A 1D array containing the ACMG scores for each sample, calculated as the\n",
    "        difference between the pathogenic and benign scores.\n",
    "    Notes:\n",
    "    ------\n",
    "    - The ACMG scores are clamped to the range [-8, 8].\n",
    "    - The input `test_results_array` is expected to have at least one column, and the\n",
    "      `p_value` should be chosen such that the calculated index is valid.\n",
    "    \"\"\"\n",
    "\n",
    "    index = int(np.ceil(p_value*test_results_array.shape[1]))\n",
    "    P_KNN_pathogenic = np.sort(test_results_array, axis=1)[:, index-1]\n",
    "    P_KNN_benign = 1- np.sort(test_results_array, axis=1)[:, -index]\n",
    "\n",
    "    if logbase is None:\n",
    "        logbase = get_logbase(Pprior) \n",
    "\n",
    "    ACMG_pathogenic_scores = Probability2ACMG_score(P_KNN_pathogenic, Pprior, logbase)\n",
    "    ACMG_benign_scores = Probability2ACMG_score(P_KNN_benign, 1-Pprior, logbase)\n",
    "\n",
    "    ACMG_pathogenic_scores[ACMG_pathogenic_scores < 0] = 0\n",
    "    ACMG_benign_scores[ACMG_benign_scores < 0] = 0\n",
    "    ACMG_pathogenic_scores[ACMG_pathogenic_scores > 8] = 8\n",
    "    ACMG_benign_scores[ACMG_benign_scores > 8] = 8\n",
    "\n",
    "    ACMG_scores = ACMG_pathogenic_scores - ACMG_benign_scores\n",
    "\n",
    "    return P_KNN_pathogenic, P_KNN_benign, ACMG_scores\n",
    "\n",
    "def Probability2ACMG_score(Ppost, Pprior, logbase=None):\n",
    "    if logbase is None:\n",
    "        logbase = get_logbase(Pprior)\n",
    "\n",
    "    Likelihood_ratio = Ppost * (1 - Pprior) / ((1 - Ppost) * Pprior)\n",
    "    ACMG_scores = 8 * np.log(Likelihood_ratio) / np.log(logbase)\n",
    "\n",
    "    return ACMG_scores\n",
    "\n",
    "\n",
    "def ACMG_score2Probability(ACMG_scores, Pprior, logbase=None):\n",
    "    if logbase is None:\n",
    "        logbase = get_logbase(Pprior)\n",
    "    \n",
    "    Pathogenic_likelihood = logbase ** (ACMG_scores / 8)\n",
    "    Pathogenic_prob = Pathogenic_likelihood * Pprior / (1 + Pprior * (Pathogenic_likelihood-1)) \n",
    "    return Pathogenic_prob\n",
    "\n",
    "def weighted_score_with_binom_ci(p_array, n_array, w, p_value=0.05):\n",
    "    from scipy.stats import binom\n",
    "    p_array = np.asarray(p_array)\n",
    "    n_array = np.asarray(n_array)\n",
    "    shape = p_array.shape\n",
    "\n",
    "    scores = np.full(shape, np.nan)\n",
    "    ci_lower = np.full(shape, np.nan)\n",
    "    ci_upper = np.full(shape, np.nan)\n",
    "\n",
    "    t_array = p_array + n_array\n",
    "\n",
    "    it = np.nditer(p_array, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        p = p_array[idx]\n",
    "        t = t_array[idx]\n",
    "\n",
    "        if t > 0:\n",
    "            pi_hat = p / t\n",
    "            ci_low, ci_up = binom.interval(1-p_value, t, pi_hat)\n",
    "            \n",
    "            def weighted(pi):\n",
    "                return pi / (pi + w * (1 - pi))\n",
    "\n",
    "            scores[idx] = weighted(pi_hat)\n",
    "            ci_lower[idx] = weighted(ci_low / t)\n",
    "            ci_upper[idx] = weighted(ci_up / t)\n",
    "        \n",
    "        it.iternext()\n",
    "    \n",
    "    return scores, ci_lower, ci_upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530ed20-0878-4ae5-aab6-f0b89376a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP53_ClinVar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644db24-d630-4e12-9a08-c7ace78a624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP53_ClinVar['ACMGLLR_DMS_trp+ESM'] = TP53_ClinVar['ACMGLLR_TP53_transcription_urn_mavedb_00001234-0-1_scores']+TP53_ClinVar['ACMGLLR_ESM1b_score']\n",
    "TP53_ClinVar['ACMGLLR_DMS_dne+ESM'] = TP53_ClinVar['ACMGLLR_TP53_DNE_urn_mavedb_00001235-a-1_scores']+TP53_ClinVar['ACMGLLR_ESM1b_score']\n",
    "# TP53_ClinVar[(#(TP53_ClinVar['ACMGLLR_DMS_trp']<TP53_ClinVar['ACMGLLR_DMS_trp_ESM']) & \\\n",
    "#               (TP53_ClinVar['ClinVar_annotation']==1))][['ACMGLLR_DMS_trp', 'ACMGLLR_DMS_trp_ESM']]\n",
    "TP53_ClinVar[(TP53_ClinVar['ClinVar_annotation']==1)][['ACMGLLR_ESM1b_score', 'ACMGLLR_TP53_DNE_urn_mavedb_00001235-a-1_scores', 'ACMGLLR_DMS_dne+ESM']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618a553-8b3a-40d4-aaeb-6e3815d674d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data[combine_data['Category'].isin(['ESM1b_score', \n",
    "                                                            'TP53_transcription_urn_mavedb_00001234-0-1_scores',\n",
    "                                                            'ESM1b_TP53_transcription_urn_mavedb_00001234-0-1_scores',\n",
    "                                                            'TP53_DNE_urn_mavedb_00001235-a-1_scores', \n",
    "                                                            'ESM1b_TP53_DNE_urn_mavedb_00001235-a-1_scores'])]\n",
    "\n",
    "combine_data['Category'] = combine_data['Category'].replace({\n",
    "    'ESM1b_score': 'ESM1b_score',\n",
    "    'TP53_transcription_urn_mavedb_00001234-0-1_scores': 'DMS_trp',\n",
    "    'ESM1b_TP53_transcription_urn_mavedb_00001234-0-1_scores': 'DMS_trp_ESM',\n",
    "    'TP53_DNE_urn_mavedb_00001235-a-1_scores': 'DMS_dne',\n",
    "    'ESM1b_TP53_DNE_urn_mavedb_00001235-a-1_scores': 'DMS_dne_ESM'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d721f6-30c0-410d-abfa-47f1580e25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "## violin plot\n",
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize=(12, 3.5))\n",
    "ax = sns.violinplot(\n",
    "    x=\"Category\",\n",
    "    y=\"Score\", \n",
    "    hue=\"Label\",   # Pathogenic and Benign \n",
    "    data=combine_data, \n",
    "    split=True,   # on each side of violin\n",
    "    inner=\"quart\", \n",
    "    palette={\"Pathogenic variants\": \"red\", \"Benign variants\": \"blue\"},\n",
    "    alpha=0.6, \n",
    "    density_norm='count',\n",
    "    hue_order=['Pathogenic variants', 'Benign variants'],\n",
    "    order=['ESM1b_score', 'DMS_dne', 'DMS_dne_ESM', 'DMS_trp', 'DMS_trp_ESM']\n",
    ")\n",
    "\n",
    "dark_gray = '0.3'\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"Category\", y=\"Score\", hue=\"Label\", data=combine_data,\n",
    "    showcaps=True,  \n",
    "    showfliers=False,\n",
    "    palette={\"Pathogenic variants\": \"pink\", \"Benign variants\": \"#bae0f5\"},\n",
    "    width=0.1, dodge=True, ax=ax,\n",
    "    whiskerprops={'color': dark_gray, 'linewidth': 1.5, 'zorder': 2},\n",
    "    capprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    medianprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    boxprops={'zorder': 2, 'edgecolor': dark_gray, 'linewidth': 1.5},\n",
    "    hue_order=['Pathogenic variants', 'Benign variants']\n",
    "\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "n_hue = combine_data[\"Label\"].nunique() \n",
    "ax.legend(handles[:n_hue], labels[:n_hue], loc=\"lower right\", fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks([-8, -6, -4, -2, 0, 2, 4, 6, 8])\n",
    "# plt.ylim([-6,11])\n",
    "plt.ylabel(\"Evidence strength (LLR)\", fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.savefig(\"Fig6A.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e56a3-a6a6-4354-b493-638fcc86d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 10\n",
    "\n",
    "Pprior = 0.22\n",
    "label = TP53_ClinVar['ClinVar_annotation'].to_numpy().astype(int)\n",
    "w_test = (1 - Pprior) * sum(label == 1) / (sum(label == 0) * Pprior) \n",
    "\n",
    "Ppost = ACMG_score2Probability(TP53_ClinVar['ACMGLLR_DMS_dne+ESM'], Pprior, logbase=1730)\n",
    "\n",
    "Post_p = np.zeros(4) \n",
    "Post_b = np.zeros(4)\n",
    "\n",
    "for j in range(4):\n",
    "    Post_p[j] = logbase ** (1 / 2 ** j) * Pprior / ((logbase ** (1 / 2 ** j) - 1) * Pprior + 1)\n",
    "    Post_b[j] = (logbase ** (1 / 2 ** j)) * (1 - Pprior) / (((logbase ** (1 / 2 ** j)) - 1) * (1 - Pprior) + 1)\n",
    "        \n",
    "Pathogenic_P_KNN_pathogenic = Ppost[label==1]\n",
    "Benign_P_KNN_pathogenic = Ppost[label==0]\n",
    "\n",
    "bins = np.linspace(0, 1, num_bins + 1)\n",
    "\n",
    "pathogenic_counts, _ = np.histogram(Pathogenic_P_KNN_pathogenic, bins=bins)\n",
    "benign_counts, _ = np.histogram(Benign_P_KNN_pathogenic, bins=bins)\n",
    "\n",
    "pathogenic_ratios, ci_lower, ci_upper = weighted_score_with_binom_ci(pathogenic_counts, benign_counts, w_test, p_value)\n",
    "\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "valid_mask = ~np.isnan(pathogenic_ratios) & ~np.isnan(ci_lower) & ~np.isnan(ci_upper)\n",
    "\n",
    "pathogenic_calibration_dict = {}\n",
    "\n",
    "pathogenic_calibration_dict['bin_centers'] = bin_centers[valid_mask]\n",
    "pathogenic_calibration_dict['ratios'] = pathogenic_ratios[valid_mask]\n",
    "pathogenic_calibration_dict['ci_lower'] = ci_lower[valid_mask]\n",
    "pathogenic_calibration_dict['ci_upper'] = ci_upper[valid_mask]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(pathogenic_calibration_dict['bin_centers'], pathogenic_calibration_dict['ratios'], \n",
    "         'o-', color='red', label='Pathogenic Probability')\n",
    "plt.fill_between(pathogenic_calibration_dict['bin_centers'], \n",
    "                 pathogenic_calibration_dict['ci_lower'], pathogenic_calibration_dict['ci_upper'], \n",
    "                 color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.xlabel(\"P-KNN Pathogenic Score\", fontsize=14)\n",
    "plt.ylabel(\"Pathogenic Probability\", fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "x_vals = np.linspace(0, 1, 100)\n",
    "plt.plot(x_vals, x_vals, label=\"y = x\", color='red', linestyle='--', alpha=0.2)\n",
    "\n",
    "for threshold in Post_p:\n",
    "    plt.axvline(x=threshold, color='orange', linestyle='--', label=f'X = {threshold}', alpha=0.2)\n",
    "    plt.axhline(y=threshold, color='orange', linestyle='--', label=f'Y = {threshold}', alpha=0.2)\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "plt.savefig(f\"Fig6E_P_Calibration.svg\", format=\"svg\")        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fd0a5-7bce-4dd9-887f-b6b4a9dc9bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894a7d7f-c211-496a-9e56-96322a2457cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e67f3e-fab1-4443-830f-e65ae216061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_samples = 145000  \n",
    "num_features = 17\n",
    "\n",
    "features = np.random.normal(loc=0, scale=1, size=(num_samples, num_features)).astype(np.float32)\n",
    "\n",
    "# Pass through a ramdom MLP and generate label\n",
    "class ComplexMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ComplexMLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, 32)\n",
    "        self.hidden2 = nn.Linear(32, 16)\n",
    "        self.hidden3 = nn.Linear(16, 8)\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden1(x))\n",
    "        x = self.activation(self.hidden2(x))\n",
    "        x = self.activation(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = ComplexMLP(num_features)\n",
    "features_tensor = torch.tensor(features)\n",
    "outputs = model(features_tensor).detach().numpy().flatten()\n",
    "\n",
    "threshold = np.median(outputs)\n",
    "labels = (outputs > threshold).astype(int)\n",
    "\n",
    "# Add noise\n",
    "features += np.random.normal(loc=0, scale=0.01, size=(num_samples, num_features)).astype(np.float32)\n",
    "\n",
    "# Split for model training, calibration and test\n",
    "X_model, X_calibration, y_model, y_calibration = train_test_split(features, labels, test_size=95000/145000, random_state=42)\n",
    "X_regularization, X_calibration, _, y_calibration = train_test_split(X_calibration, y_calibration, test_size=60000/95000, random_state=42)\n",
    "X_calibration, X_test, y_calibration, y_test = train_test_split(X_calibration, y_calibration, test_size=50000/60000, random_state=42)\n",
    "\n",
    "print(\"Model train feature:\", X_model.shape, \"Model train label:\", y_model.shape)\n",
    "print(\"Regularization feature:\", X_regularization.shape)\n",
    "print(\"Calibrate feature:\", X_calibration.shape, \"Calibrate label:\", y_calibration.shape)\n",
    "print(\"Test feature:\", X_test.shape, \"Test label:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50530fff-656a-4d5b-b3dd-ec36f3763c87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train elementary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd899f89-69c7-4176-bb51-1ba6d584c7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Exclude 2 features from training\n",
    "excluded_features = [0, 1] \n",
    "available_features = [i for i in range(num_features) if i not in excluded_features]\n",
    "\n",
    "np.random.seed(42)\n",
    "# models = []\n",
    "model_feature = []\n",
    "regularization_feature = []\n",
    "calibration_feature = []\n",
    "test_feature = []\n",
    "\n",
    "# Model parameters\n",
    "model_classes = [GaussianNB, RandomForestClassifier, GaussianNB, RandomForestClassifier, LogisticRegression, LogisticRegression]\n",
    "model_params = [\n",
    "    {}, \n",
    "    {\"n_estimators\": 100, \"min_samples_split\": 10, \"n_jobs\": -1, \"random_state\": 42},\n",
    "    {},  \n",
    "    {\"n_estimators\": 100, \"min_samples_split\": 10, \"n_jobs\": -1, \"random_state\": 42},\n",
    "    {\"random_state\": 42},\n",
    "    {\"random_state\": 42}\n",
    "]\n",
    "\n",
    "num_tools = 50\n",
    "num_rounds = (num_tools//6)+1 \n",
    "\n",
    "for round_idx in range(num_rounds):\n",
    "    print(f\"Training round {round_idx + 1}/{num_rounds}\")\n",
    "    for i, (model_class, params) in enumerate(zip(model_classes, model_params)):\n",
    "        selected_features = np.sort(np.random.choice(available_features, 12 - round_idx//2, replace=False))\n",
    "        # selected_features = np.sort(np.random.choice(available_features, 14 - round_idx//2, replace=False))\n",
    "        X_model_subset = X_model[:, selected_features]\n",
    "        X_regularization_subset = X_regularization[:, selected_features]\n",
    "        X_calibration_subset = X_calibration[:, selected_features]\n",
    "        X_test_subset = X_test[:, selected_features]\n",
    "\n",
    "        model = model_class(**params)\n",
    "        model.fit(X_model_subset, y_model)\n",
    "        \n",
    "        y_model_prob = model.predict_proba(X_model_subset)[:, 1]\n",
    "        y_regularization_prob = model.predict_proba(X_regularization_subset)[:, 1]\n",
    "        y_calibration_prob = model.predict_proba(X_calibration_subset)[:, 1]\n",
    "        y_test_prob = model.predict_proba(X_test_subset)[:, 1]\n",
    "\n",
    "        auc_model = roc_auc_score(y_model, y_model_prob)\n",
    "        auc_calibration = roc_auc_score(y_calibration, y_calibration_prob)\n",
    "        auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "        \n",
    "        print(f\"Model {round_idx*6+i} ({model_class.__name__}) trained with {len(selected_features)} features {selected_features}.\")\n",
    "        print(f\"Model train AUC: {auc_model:.4f},  Calibrate AUC: {auc_calibration:.4f}, Calibrate test AUC: {auc_test:.4f}\")\n",
    "        model_feature.append(y_model_prob)\n",
    "        regularization_feature.append(y_regularization_prob)\n",
    "        calibration_feature.append(y_calibration_prob)\n",
    "        test_feature.append(y_test_prob)\n",
    "        # models.append(model)\n",
    "\n",
    "        if round_idx*6+i+1 >= num_tools: break\n",
    "\n",
    "model_feature = np.column_stack(model_feature)\n",
    "regularization_feature = np.column_stack(regularization_feature)\n",
    "calibration_feature = np.column_stack(calibration_feature)\n",
    "test_feature = np.column_stack(test_feature)\n",
    "\n",
    "print(\"Tool calibration\", calibration_feature.shape, \"Tool test\", test_feature.shape, \"Tool regularization\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a066f16-e852-4f10-a057-bb4365cb1f19",
   "metadata": {},
   "source": [
    "## silhouette score and mutual information of each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7108801b-aa95-4172-b452-d576a35823cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import copy\n",
    "from P_KNN_GPU import silhouette_score_1d_torch, get_score_rank_torch\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "calibration_feature_rank = get_score_rank_torch(torch.tensor(calibration_feature), torch.tensor(calibration_feature))\n",
    "calibration_label_bk = y_calibration\n",
    "\n",
    "silhouette_raw_list = []\n",
    "silhouette_rank_list = []\n",
    "MI_raw_list = []\n",
    "MI_rank_list = []\n",
    "AUC_list = []\n",
    "\n",
    "for i in range(calibration_feature_rank.shape[1]): \n",
    "    select_feature = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = torch.tensor(calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1))\n",
    "    calibration_array_rank = calibration_feature_rank[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = torch.tensor(copy.deepcopy(calibration_label_bk[valid_calibration_idx]))\n",
    "\n",
    "    print(f\"Tool {i}, calibration size: {calibration_array.shape[0]}\")\n",
    "    silhouette_raw = silhouette_score_1d_torch(calibration_array, calibration_label)\n",
    "    silhouette_rank = silhouette_score_1d_torch(calibration_array_rank, calibration_label)\n",
    "    MI_raw = mutual_info_classif(calibration_array, calibration_label)\n",
    "    MI_rank = mutual_info_classif(calibration_array_rank, calibration_label)\n",
    "    AUC = roc_auc_score(calibration_label, calibration_array_rank)\n",
    "    \n",
    "    print('silhouette_raw', silhouette_raw)\n",
    "    print('silhouette_rank', silhouette_rank)\n",
    "    print('mutual information raw', MI_raw[0])\n",
    "    print('mutual information rank', MI_rank[0])\n",
    "    print('AUC', AUC)\n",
    "\n",
    "    silhouette_raw_list.append(silhouette_raw) \n",
    "    silhouette_rank_list.append(silhouette_rank) \n",
    "    MI_raw_list.append(MI_raw[0])\n",
    "    MI_rank_list.append(MI_rank[0])\n",
    "    AUC_list.append(AUC)\n",
    "\n",
    "    red_mask = calibration_label == 1\n",
    "    blue_mask = calibration_label == 0\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    axes[0].hist(calibration_array[red_mask], bins=30, color='red', alpha=0.6, label='Label 1')\n",
    "    axes[0].hist(calibration_array[blue_mask], bins=30, color='blue', alpha=0.6, label='Label 0')\n",
    "    axes[0].set_title(f\"Histogram of tool {i}\")\n",
    "    axes[0].set_xlabel(\"Calibration Array Values\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].hist(calibration_array_rank[red_mask], bins=30, color='red', alpha=0.6, label='Label 1')\n",
    "    axes[1].hist(calibration_array_rank[blue_mask], bins=30, color='blue', alpha=0.6, label='Label 0')\n",
    "    axes[1].set_title(f\"Histogram of Ranked tool {i}\")\n",
    "    axes[1].set_xlabel(\"Calibration Array Rank Values\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(MI_raw_list, silhouette_raw_list, alpha=0.7, edgecolors='k')\n",
    "plt.scatter(MI_rank_list, silhouette_rank_list, alpha=0.7, edgecolors='m')\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Scatter Plot of Mutual Information vs. Silhouette Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99460ea8-63f9-47ac-bf48-658b8ce6d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"strongest to weakest\")\n",
    "print(np.argsort(AUC_list)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f26d9-864f-4b44-877c-6102c8785bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(MI_raw_list, silhouette_raw_list, alpha=0.7, label = \"raw\")\n",
    "plt.scatter(MI_rank_list, silhouette_rank_list, alpha=0.7, label = \"rank\")\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Scatter Plot of Mutual Information vs. Silhouette Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd7f42-a0f9-47a2-a6c6-f9bc2cd73f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(MI_raw_list, AUC_list, alpha=0.7, label = \"raw\")\n",
    "plt.scatter(MI_rank_list, AUC_list, alpha=0.7, label = \"rank\")\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"Scatter Plot of Mutual Information vs. AUC\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85090930-9956-4314-98fc-79d2e8d6389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/model_feature.npy', model_feature)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/model_label.npy', y_model)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy', calibration_feature)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy', y_calibration)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy', test_feature)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy', y_test)\n",
    "np.save('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy', regularization_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4c4fa-30bf-4d67-ae64-41b4d0ca74bc",
   "metadata": {},
   "source": [
    "# Single Tool 1D calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7fdb75-6726-4a80-93c5-cbbe6e894eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75672575-762b-4b21-addb-2986f5053e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result_1D\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441 \n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "normalization = None\n",
    "impute = False\n",
    "mi_scaling = False\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "best_mean_evidence_strength = 0\n",
    "mean_evidence_strength_list = []\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in range(calibration_feature.shape[1]):    \n",
    "    select_feature = i\n",
    "    condition_string = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]) \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature].reshape(-1, 1)\n",
    "    calibration_label = copy.deepcopy(y_calibration[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:,select_feature])\n",
    "    test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "    test_label = copy.deepcopy(y_test[valid_test_idx])\n",
    "\n",
    "    valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature])\n",
    "    regularization_array = regularization_feature[valid_regularization_idx][:,select_feature].reshape(-1, 1)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Tool {condition_string}\")\n",
    "    print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                     calibration_label, Pprior, w_calibration, \n",
    "                                                     n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                     normalization, impute, mi_scaling, n_bootstrap, batch_size)\n",
    "\n",
    "    np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_singletool_{condition_string}.npy', test_results_array)\n",
    "\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_singletool_{condition_string}.npy')\n",
    "\n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result_1D(test_results_array,\n",
    "                                                                                                      test_array,\n",
    "                                                                                                      test_label, \n",
    "                                                                                                      p_value, \n",
    "                                                                                                      Pprior, \n",
    "                                                                                                      logbase, \n",
    "                                                                                                      category = condition_string, \n",
    "                                                                                                      show_plot=True, \n",
    "                                                                                                      save_name=None)\n",
    "    \n",
    "\n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "    mean_evidence_strength = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean() + evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "\n",
    "    pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "    benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "    mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "    \n",
    "    print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "    mean_evidence_strength_list.append(mean_evidence_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d97d32-8ac1-49fe-81c9-90c1991ee621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"strongest to weakest\")\n",
    "print(np.argsort(mean_evidence_strength_list)[::-1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ce71eed-887a-408d-bfbb-52af9e673793",
   "metadata": {},
   "source": [
    "strongest to weakest\n",
    "by 1D calibration\n",
    "[ 3  9  1 15 21 22 19 14 13 12  2 33  0 45  5 30 42  4  6 17 23 20 36 47\n",
    " 38 31 37  7 49 28 46 18  8 27 25 24 48 29 44 11 32 39 10 41 34 43 40 35\n",
    " 26 16]\n",
    "\n",
    "by AUC\n",
    "[ 9  3 21  1 15 19 13 14 45 12  0 33  2 22 30 42  5 17  6  4 36 20 23 38\n",
    " 47 31  7 37 49 27  8 18 46 25 28 24 11 29 39 44 32 48 10 43 41 34 40 35\n",
    " 26 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf6083-9349-4bd2-975c-ddfb1e08e04e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Different number of tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948179d-c614-4a5b-a4fb-c8a2cf7f1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d18c1c-dbe2-4c75-9009-45dadfe7ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pprior = 0.0441 # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "pipeline_dict = {\n",
    "    \"rank_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"rank_noMI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": False,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"z_MI\": {\n",
    "        \"normalization\": \"z\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"z_noMI\": {\n",
    "        \"normalization\": \"z\",\n",
    "        \"mi_scaling\": False,\n",
    "        \"impute\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "ACMG_score_dict = {\n",
    "    \"rank_MI\": [],\n",
    "    \"rank_noMI\": [],\n",
    "    \"z_MI\": [],\n",
    "    \"z_noMI\": []\n",
    "}\n",
    "\n",
    "category_dict = {\n",
    "    \"rank_MI\": \"ranking + MI\",\n",
    "    \"rank_noMI\": \"ranking, no MI\",\n",
    "    \"z_MI\": \"z-score + MI\",\n",
    "    \"z_noMI\": \"z-score, no MI\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e1aa9-e3b1-4016-8a0d-38d01c472cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "random.seed(42)\n",
    "sequence=random.sample(range(50), 50)\n",
    "print(sequence)\n",
    "num_tools = [2,3,4,6,8,10,13,15,20,25,30,40,50]\n",
    "\n",
    "for i in num_tools:\n",
    "    select_feature = sequence[:i]\n",
    "    condition_string = i\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]).any(axis=1)  \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature]\n",
    "    calibration_label = copy.deepcopy(y_calibration[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:,select_feature]).any(axis=1) \n",
    "    test_array = test_feature[valid_test_idx][:,select_feature]\n",
    "    test_label = y_test[valid_test_idx]\n",
    "\n",
    "    valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature]).any(axis=1) \n",
    "    regularization_array = regularization_feature[valid_regularization_idx][:,select_feature]\n",
    "\n",
    "    print(f\"{i} tools:, {select_feature}\")\n",
    "    print(f\"train size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    best_mean_evidence_strength = 0\n",
    "    \n",
    "    for pipeline_name, config in pipeline_dict.items():\n",
    "        print(pipeline_name)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                         calibration_label, Pprior, w_calibration, \n",
    "                                                         n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                         config[\"normalization\"], config[\"impute\"], config[\"mi_scaling\"], \n",
    "                                                         n_bootstrap, batch_size)\n",
    "\n",
    "        np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy', test_results_array)\n",
    "\n",
    "        test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy')\n",
    "\n",
    "        P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "        evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                        test_label, \n",
    "                                                                                                        p_value, \n",
    "                                                                                                        Pprior, \n",
    "                                                                                                        logbase, \n",
    "                                                                                                        category = f\"{condition_string} tools\\n{pipeline_name}\", \n",
    "                                                                                                        show_plot=True, \n",
    "                                                                                                        save_name=None)\n",
    "\n",
    "        combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "        pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "        benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "        mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "\n",
    "        if mean_evidence_strength >  best_mean_evidence_strength:\n",
    "            best_mean_evidence_strength = mean_evidence_strength\n",
    "            best_pipeline = pipeline_name\n",
    "        \n",
    "        print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "        print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "        ACMG_score_dict[pipeline_name].append(mean_evidence_strength)\n",
    "\n",
    "\n",
    "    print('Best pipeline', best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c98710-a803-4e34-a7cd-989132ea556c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "colors = [\"#006400\", \"#90EE90\", \"#FFA500\", \"#FFDAB9\"]\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "for i, (key, y_values) in enumerate(ACMG_score_dict.items()):\n",
    "    plt.plot(num_tools, y_values, marker='o', linestyle='-', color=colors[i], label=category_dict[key])\n",
    "\n",
    "plt.xlabel(\"Number of underlying tools\", fontsize=14)\n",
    "plt.ylabel(\"Mean evidence strength (LLR)\", fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=14)  \n",
    "plt.tight_layout()\n",
    "sns.despine(top=True, right=True)\n",
    "plt.savefig(\"Fig2A.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca67db2-9437-47e4-a59b-716c8c6bbf06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fraction of highly informative tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9543e-39b4-476e-a2fb-05e8a57d1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524c944-0bf1-4f2c-9f66-77ae3361d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pprior = 0.0441 # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "pipeline_dict = {\n",
    "    \"rank_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"rank_noMI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": False,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"z_MI\": {\n",
    "        \"normalization\": \"z\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    },\n",
    "    \"z_noMI\": {\n",
    "        \"normalization\": \"z\",\n",
    "        \"mi_scaling\": False,\n",
    "        \"impute\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "ACMG_score_dict = {\n",
    "    \"rank_MI\": [],\n",
    "    \"rank_noMI\": [],\n",
    "    \"z_MI\": [],\n",
    "    \"z_noMI\": []\n",
    "}\n",
    "\n",
    "category_dict = {\n",
    "    \"rank_MI\": \"ranking + MI\",\n",
    "    \"rank_noMI\": \"ranking, no MI\",\n",
    "    \"z_MI\": \"z-score + MI\",\n",
    "    \"z_noMI\": \"z-score, no MI\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9694a81-a96c-4ec6-b6f6-37c924ca3ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "good_tool = [9, 3, 21, 1, 15, 19, 13, 14, 45, 12, 0, 33, 2, 22, 30]\n",
    "bad_tool=[24, 11, 29, 39, 44, 32, 48, 10, 43, 41, 34, 40, 35, 26, 16]\n",
    "\n",
    "for i in [0,1,3,6,9,12,14,15]:\n",
    "    select_feature = good_tool[:i]+bad_tool[i:]\n",
    "    condition_string = f\"{i}_goodtools\"\n",
    "\n",
    "    valid_calibration_idx = ~np.isnan(calibration_feature[:,select_feature]).any(axis=1)  \n",
    "    calibration_array = calibration_feature[valid_calibration_idx][:,select_feature]\n",
    "    calibration_label = copy.deepcopy(y_calibration[valid_calibration_idx])\n",
    "\n",
    "    valid_test_idx = ~np.isnan(test_feature[:,select_feature]).any(axis=1) \n",
    "    test_array = test_feature[valid_test_idx][:,select_feature]\n",
    "    test_label = y_test[valid_test_idx]\n",
    "\n",
    "    valid_regularization_idx = ~np.isnan(regularization_feature[:,select_feature]).any(axis=1) \n",
    "    regularization_array = regularization_feature[valid_regularization_idx][:,select_feature]\n",
    "\n",
    "    print(f\"{i} good tools/15:, {select_feature}\")\n",
    "    print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    best_mean_evidence_strength = 0\n",
    "    \n",
    "    for pipeline_name, config in pipeline_dict.items():\n",
    "        print(pipeline_name)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                         calibration_label, Pprior, w_calibration, \n",
    "                                                         n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                         config[\"normalization\"], config[\"impute\"], config[\"mi_scaling\"], \n",
    "                                                         n_bootstrap, batch_size)\n",
    "\n",
    "        np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy', test_results_array)\n",
    "\n",
    "        test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy')\n",
    "\n",
    "        P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "        evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                        test_label, \n",
    "                                                                                                        p_value, \n",
    "                                                                                                        Pprior, \n",
    "                                                                                                        logbase, \n",
    "                                                                                                        category = f\"{condition_string} tools\\n{pipeline_name}\", \n",
    "                                                                                                        show_plot=True, \n",
    "                                                                                                        save_name=None)\n",
    "\n",
    "        combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "        pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "        benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "        mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "        \n",
    "        if mean_evidence_strength >  best_mean_evidence_strength:\n",
    "            best_mean_evidence_strength = mean_evidence_strength\n",
    "            best_pipeline = pipeline_name\n",
    "        \n",
    "        print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "        print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "        ACMG_score_dict[pipeline_name].append(mean_evidence_strength)\n",
    "\n",
    "\n",
    "    print('Best pipeline', best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c51922-7a83-4b60-8936-46df2631a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "colors = [\"#006400\", \"#90EE90\", \"#FFA500\", \"#FFDAB9\"]\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "for i, (key, y_values) in enumerate(ACMG_score_dict.items()):\n",
    "    plt.plot([0,1,3,6,9,12,14,15], y_values, marker='o', linestyle='-', color=colors[i], label=category_dict[key])\n",
    "\n",
    "plt.xlabel(\"Number of highly informative tools (Out of 15 total))\", fontsize = 14)\n",
    "plt.ylabel(\"Mean evidence strength (LLR)\", fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize = 14) \n",
    "plt.tight_layout()\n",
    "sns.despine(top=True, right=True)\n",
    "plt.savefig(\"Fig2B.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa4fa1-8eb8-4954-a209-9c85d0cbeeff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Different pattern of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd09646-1bee-47b6-8471-f01a1e9bad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296d802-8e49-4c87-b29a-0bb1bf5ba418",
   "metadata": {},
   "source": [
    "## Function for generating missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d4bdd-77fd-48ad-b688-2580d82f9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_missing_values(data, missing_rates, method=\"random\", protected_fraction=0.5, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    data_with_nan = data.copy()\n",
    "    num_rows, num_cols = data.shape\n",
    "\n",
    "    all_indices = np.arange(num_rows)\n",
    "    num_protected = int(num_rows * protected_fraction)\n",
    "    protected_indices = rng.choice(all_indices, size=num_protected, replace=False)\n",
    "    non_protected_indices = np.setdiff1d(all_indices, protected_indices)\n",
    "\n",
    "    for col in range(num_cols):\n",
    "        num_missing = int(missing_rates[col] * num_rows)\n",
    "        eligible_indices = non_protected_indices.copy()\n",
    "\n",
    "        if method == \"largest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[int(num_rows * 0.5):])\n",
    "        elif method == \"smallest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[:int(num_rows * 0.5)])\n",
    "        elif method == \"bulk\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            q_low = rng.uniform(0, 0.5)\n",
    "            q_high = q_low + 0.5\n",
    "            lower_idx = int(q_low * num_rows)\n",
    "            upper_idx = int(q_high * num_rows)\n",
    "            bulk_range = sorted_indices[lower_idx:upper_idx]\n",
    "            eligible_indices = np.intersect1d(eligible_indices, bulk_range)\n",
    "        elif method != \"random\":\n",
    "            raise ValueError(f\"Invalid method: {method}\")\n",
    "\n",
    "        missing_indices = rng.choice(\n",
    "            eligible_indices,\n",
    "            size=min(num_missing, len(eligible_indices)),\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        data_with_nan[missing_indices, col] = np.nan\n",
    "\n",
    "    return data_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afe458-8c14-4001-a908-434c4d1d1582",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3b97a-45fc-44f0-9914-d54a5cc14f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "Pprior = 0.0441 # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "protected_fraction = 0\n",
    "random_state = 42\n",
    "\n",
    "np.random.seed(random_state)\n",
    "missing_rate_array = np.random.uniform(0, 0.25, size=calibration_feature.shape[1])\n",
    "print(\"missing_rate_array\")\n",
    "print(missing_rate_array)\n",
    "\n",
    "random.seed(random_state)\n",
    "select_feature=random.sample(range(50), 15)\n",
    "print(\"select_feature\")\n",
    "print(select_feature)\n",
    "\n",
    "pipeline_dict = {\n",
    "    \"rank_ImputeMissing_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": True\n",
    "    },\n",
    "    \"rank_ExcludeMissing_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "ACMG_score_dict = {\n",
    "    \"rank_ImputeMissing_MI\": [],\n",
    "    \"rank_ExcludeMissing_MI\": []\n",
    "}\n",
    "\n",
    "category_dict = {\n",
    "    \"rank_ExcludeMissing_MI\": \"Exclude variants with missing values\",\n",
    "    \"rank_ImputeMissing_MI\": \"Impute missing values\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3d97f-ddb9-43cb-becc-fe5e7d81c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "condition_list = ['random', \"largest\", \"smallest\", \"bulk\"]\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in range(4):\n",
    "    condition_string = f\"{condition_list[i]}missing\"\n",
    "    best_mean_evidence_strength = 0\n",
    "    \n",
    "    for pipeline_name, config in pipeline_dict.items():\n",
    "        print(condition_string, pipeline_name)\n",
    "        calibration_array = apply_missing_values(calibration_feature, missing_rate_array, method=condition_list[i], \n",
    "                                           protected_fraction=protected_fraction, random_state=random_state)    \n",
    "        test_array = apply_missing_values(test_feature, missing_rate_array, method=condition_list[i], \n",
    "                                          protected_fraction=protected_fraction, random_state=random_state)\n",
    "        regularization_array = apply_missing_values(regularization_feature, missing_rate_array, method=condition_list[i], \n",
    "                                            protected_fraction=protected_fraction, random_state=random_state)\n",
    "\n",
    "        valid_calibration_idx = ~np.isnan(calibration_array[:,select_feature]).all(axis=1)  \n",
    "        calibration_array = calibration_array[valid_calibration_idx][:,select_feature]\n",
    "        calibration_label = copy.deepcopy(y_calibration[valid_calibration_idx])\n",
    "    \n",
    "        valid_test_idx = ~np.isnan(test_array[:,select_feature]).all(axis=1) \n",
    "        test_array = test_array[valid_test_idx][:,select_feature]\n",
    "        test_label = y_test[valid_test_idx]\n",
    "    \n",
    "        valid_regularization_idx = ~np.isnan(regularization_array[:,select_feature]).all(axis=1) \n",
    "        regularization_array = regularization_array[valid_regularization_idx][:,select_feature]\n",
    "        # print(np.isnan(calibration_array).sum(axis=0))\n",
    "        print(f\"Missing Pattern: {condition_list[i]}\")\n",
    "        print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "        test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                         calibration_label, Pprior, w_calibration, \n",
    "                                                         n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                         config[\"normalization\"], config[\"impute\"], config[\"mi_scaling\"], \n",
    "                                                         n_bootstrap, batch_size)\n",
    "\n",
    "        np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy', test_results_array)\n",
    "\n",
    "        test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy')\n",
    "\n",
    "        P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "        evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                        test_label, \n",
    "                                                                                                        p_value, \n",
    "                                                                                                        Pprior, \n",
    "                                                                                                        logbase, \n",
    "                                                                                                        category = f\"{condition_string} tools\\n{pipeline_name}\", \n",
    "                                                                                                        show_plot=True, \n",
    "                                                                                                        save_name=None)\n",
    "\n",
    "        combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "        pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "        benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "        mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "        \n",
    "        if mean_evidence_strength >  best_mean_evidence_strength:\n",
    "            best_mean_evidence_strength = mean_evidence_strength\n",
    "            best_pipeline = pipeline_name\n",
    "\n",
    "        print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "        print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "        ACMG_score_dict[pipeline_name].append(mean_evidence_strength)\n",
    "\n",
    "    print('Best pipeline', best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eed343-3d97-4a8c-a4d4-2d8ab29c284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "colors = cm.tab10(np.linspace(0, 1, len(ACMG_score_dict))) \n",
    "x = np.arange(len(condition_list))\n",
    "\n",
    "bar_width = 0.2\n",
    "\n",
    "plt.figure(figsize=(6, 3.5)) \n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "for i, (key, y_values) in enumerate(ACMG_score_dict.items()):\n",
    "    plt.bar(x + i * bar_width, y_values, width=bar_width, color=colors[i], alpha=0.7, label=category_dict[key])\n",
    "\n",
    "plt.xticks(x + bar_width / 2, condition_list) \n",
    "plt.xlabel(\"Simulation of Missing Values\", fontsize=14)\n",
    "plt.ylabel(\"Mean evidence strength (LLR)\", fontsize=14)\n",
    "plt.legend(loc='upper left', fontsize=13)\n",
    "plt.ylim([1,3])\n",
    "new_labels = [\"Random\\nvalues\", \"Largest\\nvalues\", \"Smallest\\nvalues\", \"Midrange\\nvalues\"] \n",
    "plt.xticks(x + bar_width / 2, new_labels) \n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True, right=True)\n",
    "plt.savefig(\"Fig2D.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eba852-777d-41dc-bd25-8fb8ea339087",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Different Fraction of missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109607c-ec2a-4ba6-b8c2-badca4bf5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb9ff0-49ec-47ef-87d9-7a0dd839f19a",
   "metadata": {},
   "source": [
    "## Function for generating missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48f705-87fe-4431-9eac-17455ad72f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_missing_values(data, missing_rates, method=\"random\", protected_fraction=0.5, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    data_with_nan = data.copy()\n",
    "    num_rows, num_cols = data.shape\n",
    "\n",
    "    all_indices = np.arange(num_rows)\n",
    "    num_protected = int(num_rows * protected_fraction)\n",
    "    protected_indices = rng.choice(all_indices, size=num_protected, replace=False)\n",
    "    non_protected_indices = np.setdiff1d(all_indices, protected_indices)\n",
    "\n",
    "    for col in range(num_cols):\n",
    "        num_missing = int(missing_rates[col] * num_rows)\n",
    "        eligible_indices = non_protected_indices.copy()\n",
    "\n",
    "        if method == \"largest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[int(num_rows * 0.5):])\n",
    "        elif method == \"smallest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[:int(num_rows * 0.5)])\n",
    "        elif method == \"bulk\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            q_low = rng.uniform(0, 0.5)\n",
    "            q_high = q_low + 0.5\n",
    "            lower_idx = int(q_low * num_rows)\n",
    "            upper_idx = int(q_high * num_rows)\n",
    "            bulk_range = sorted_indices[lower_idx:upper_idx]\n",
    "            eligible_indices = np.intersect1d(eligible_indices, bulk_range)\n",
    "        elif method != \"random\":\n",
    "            raise ValueError(f\"Invalid method: {method}\")\n",
    "\n",
    "        #  eligible  NaN  index\n",
    "        missing_indices = rng.choice(\n",
    "            eligible_indices,\n",
    "            size=min(num_missing, len(eligible_indices)),\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        data_with_nan[missing_indices, col] = np.nan\n",
    "\n",
    "    return data_with_nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e717c9-3935-4902-a92d-63becdb82a47",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cb34c-e619-420b-9b11-56bfd02520e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "Pprior = 0.0441 # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "protected_fraction = 0\n",
    "random_state = 42\n",
    "\n",
    "np.random.seed(random_state)\n",
    "missing_rate_array = np.random.uniform(0, 0.25, size=calibration_feature.shape[1])\n",
    "print(\"missing_rate_array\")\n",
    "print(missing_rate_array)\n",
    "\n",
    "random.seed(random_state)\n",
    "select_feature=random.sample(range(50), 15)\n",
    "print(\"select_feature\")\n",
    "print(select_feature)\n",
    "\n",
    "pipeline_dict = {\n",
    "    \"rank_ImputeMissing_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": True\n",
    "    },\n",
    "    \"rank_ExcludeMissing_MI\": {\n",
    "        \"normalization\": \"rank\",\n",
    "        \"mi_scaling\": True,\n",
    "        \"impute\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "ACMG_score_dict = {\n",
    "    \"rank_ImputeMissing_MI\": [],\n",
    "    \"rank_ExcludeMissing_MI\": []\n",
    "}\n",
    "\n",
    "category_dict = {\n",
    "    \"rank_ExcludeMissing_MI\": \"Exclude variants with missing values\",\n",
    "    \"rank_ImputeMissing_MI\": \"Impute missing values\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf78bb-a07e-4f9f-a22e-479a7e50e4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result\n",
    "import copy\n",
    "\n",
    "missing_fraction = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in range(7):\n",
    "    condition_string = f\"{missing_fraction[i]}missing\"\n",
    "    np.random.seed(42)\n",
    "    missing_rate_array = np.random.uniform(0, missing_fraction[i], size=calibration_feature.shape[1])\n",
    "    \n",
    "    best_mean_evidence_strength = 0\n",
    "    \n",
    "    for pipeline_name, config in pipeline_dict.items():\n",
    "        print(condition_string, pipeline_name)\n",
    "        calibration_array = apply_missing_values(calibration_feature, missing_rate_array, method=\"random\", \n",
    "                                           protected_fraction=protected_fraction, random_state=random_state)    \n",
    "        test_array = apply_missing_values(test_feature, missing_rate_array, method=\"random\", \n",
    "                                          protected_fraction=protected_fraction, random_state=random_state)\n",
    "        regularization_array = apply_missing_values(regularization_feature, missing_rate_array, method=\"random\", \n",
    "                                            protected_fraction=protected_fraction, random_state=random_state)\n",
    "\n",
    "        valid_calibration_idx = ~np.isnan(calibration_array[:,select_feature]).all(axis=1)  \n",
    "        calibration_array = calibration_array[valid_calibration_idx][:,select_feature]\n",
    "        calibration_label = copy.deepcopy(y_calibration[valid_calibration_idx])\n",
    "    \n",
    "        valid_test_idx = ~np.isnan(test_array[:,select_feature]).all(axis=1) \n",
    "        test_array = test_array[valid_test_idx][:,select_feature]\n",
    "        test_label = y_test[valid_test_idx]\n",
    "    \n",
    "        valid_regularization_idx = ~np.isnan(regularization_array[:,select_feature]).all(axis=1) \n",
    "        regularization_array = regularization_array[valid_regularization_idx][:,select_feature]\n",
    "\n",
    "        print(f\"Missing rate: {missing_fraction[i]}\")\n",
    "        print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "        test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                         calibration_label, Pprior, w_calibration, \n",
    "                                                         n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                         config[\"normalization\"], config[\"impute\"], config[\"mi_scaling\"], \n",
    "                                                         n_bootstrap, batch_size)\n",
    "\n",
    "        np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy', test_results_array)\n",
    "\n",
    "        test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}_{pipeline_name}.npy')\n",
    "\n",
    "        P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "        evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                        test_label, \n",
    "                                                                                                        p_value, \n",
    "                                                                                                        Pprior, \n",
    "                                                                                                        logbase, \n",
    "                                                                                                        category = f\"{condition_string} tools\\n{pipeline_name}\", \n",
    "                                                                                                        show_plot=True, \n",
    "                                                                                                        save_name=None)\n",
    "\n",
    "        combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "        pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "        benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "        mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "        \n",
    "        if mean_evidence_strength >  best_mean_evidence_strength:\n",
    "            best_mean_evidence_strength = mean_evidence_strength\n",
    "            best_pipeline = pipeline_name\n",
    " \n",
    "        print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "        print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "        ACMG_score_dict[pipeline_name].append(mean_evidence_strength)\n",
    "\n",
    "    print('Best pipeline', best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d984a38-fbe3-44cd-8ddd-7699752ae7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "colors = cm.tab10(np.linspace(0, 1, len(ACMG_score_dict))) \n",
    "\n",
    "bar_width = 0.2\n",
    "\n",
    "plt.figure(figsize=(6, 3.3)) \n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "for i, (key, y_values) in enumerate(ACMG_score_dict.items()):\n",
    "    plt.plot([5, 10, 15, 20, 25, 30, 40], y_values, marker='o', linestyle='-', color=colors[i], alpha=0.7, label=category_dict[key])\n",
    "    \n",
    "plt.xlabel(\"Max % of Missing Values per Tool\", fontsize=14)\n",
    "plt.ylabel(\"Mean evidence strength (LLR)\", fontsize=14)\n",
    "# plt.ylim([3.5,4.5])\n",
    "plt.legend(loc='lower left', fontsize=13)\n",
    "# plt.grid(True) \n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine(top=True, right=True)\n",
    "plt.savefig(\"Fig2C.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49334835-03b2-4179-ba26-f4e10543aa82",
   "metadata": {},
   "source": [
    "# Contamination tool training data\n",
    "Testing final pipeline Rank, KNN Impute, Mutual Information Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d36de-54d6-4003-856a-00a373ae1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/model_feature.npy')\n",
    "y_model = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/model_label.npy')\n",
    "print(\"model_feature.shape:\", model_feature.shape)\n",
    "print(\"model_label.shape:\", y_model.shape)\n",
    "\n",
    "calibration_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_feature.npy')\n",
    "y_calibration = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/calibration_label.npy')\n",
    "test_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_feature.npy')\n",
    "y_test = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/test_label.npy')\n",
    "regularization_feature = np.load('/gpfs/home/pl2948/VariantInterpretation/KNNsimulation/regularization_feature.npy')\n",
    "\n",
    "print(\"calibration_feature.shape:\", calibration_feature.shape)\n",
    "print(\"calibration_label.shape:\", y_calibration.shape)\n",
    "print(\"test_feature.shape:\", test_feature.shape)\n",
    "print(\"test_label.shape:\", y_test.shape)\n",
    "print(\"regularization_feature.shape:\", regularization_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e465b-0bea-4388-8216-a5b9f767d3f2",
   "metadata": {},
   "source": [
    "## Generate data with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50059ae-2be2-4db6-bdac-c64b434466ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def apply_missing_values(data, missing_rates, method=\"random\", protected_fraction=0.5, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    data_with_nan = data.copy()\n",
    "    num_rows, num_cols = data.shape\n",
    "\n",
    "    all_indices = np.arange(num_rows)\n",
    "    num_protected = int(num_rows * protected_fraction)\n",
    "    protected_indices = rng.choice(all_indices, size=num_protected, replace=False)\n",
    "    non_protected_indices = np.setdiff1d(all_indices, protected_indices)\n",
    "\n",
    "    for col in range(num_cols):\n",
    "        num_missing = int(missing_rates[col] * num_rows)\n",
    "        eligible_indices = non_protected_indices.copy()\n",
    "\n",
    "        if method == \"largest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[int(num_rows * 0.5):])\n",
    "        elif method == \"smallest\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            eligible_indices = np.intersect1d(eligible_indices, sorted_indices[:int(num_rows * 0.5)])\n",
    "        elif method == \"bulk\":\n",
    "            sorted_indices = np.argsort(data[:, col])\n",
    "            q_low = rng.uniform(0, 0.5)\n",
    "            q_high = q_low + 0.5\n",
    "            lower_idx = int(q_low * num_rows)\n",
    "            upper_idx = int(q_high * num_rows)\n",
    "            bulk_range = sorted_indices[lower_idx:upper_idx]\n",
    "            eligible_indices = np.intersect1d(eligible_indices, bulk_range)\n",
    "        elif method != \"random\":\n",
    "            raise ValueError(f\"Invalid method: {method}\")\n",
    "\n",
    "        #  eligible  NaN  index\n",
    "        missing_indices = rng.choice(\n",
    "            eligible_indices,\n",
    "            size=min(num_missing, len(eligible_indices)),\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        data_with_nan[missing_indices, col] = np.nan\n",
    "\n",
    "    return data_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622900f8-3b2f-4ce4-a5ae-6e329b895d4c",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796d2c7-1843-4efe-8be9-c4c236de6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "Pprior = 0.0441 # Prior probability of pathogenicity (changes w/ c)\n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100   # minimum number of clinvar variants in a local window\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "normalization = \"rank\"\n",
    "impute = True\n",
    "mi_scaling = True\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "random.seed(42)\n",
    "select_feature=random.sample(range(50), 15)\n",
    "print(\"select_feature\")\n",
    "print(select_feature)\n",
    "\n",
    "protected_fraction = 0\n",
    "random_state = 42\n",
    "\n",
    "np.random.seed(42)\n",
    "missing_rate_array = np.random.uniform(0, 0.25, size=calibration_feature.shape[1])\n",
    "print(\"missing_rate_array\")\n",
    "print(missing_rate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202c9c6-5348-452b-a63a-0c02646bfe76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from P_KNN_GPU import evaluate_result\n",
    "\n",
    "combine_data = pd.DataFrame()\n",
    "\n",
    "for i in range(7):\n",
    "    print(i/2)\n",
    "    \n",
    "    condition_string = f\"{i/2:.1f}_modeltrain\"\n",
    "    print(condition_string)\n",
    "\n",
    "    calibration_array = apply_missing_values(calibration_feature, missing_rate_array, method=\"random\", \n",
    "                                   protected_fraction=protected_fraction, random_state=random_state)    \n",
    "    test_array = apply_missing_values(test_feature, missing_rate_array, method=\"random\", \n",
    "                                      protected_fraction=protected_fraction, random_state=random_state)\n",
    "    regularization_array = apply_missing_values(regularization_feature, missing_rate_array, method=\"random\", \n",
    "                                        protected_fraction=protected_fraction, random_state=random_state)\n",
    "    model_array = apply_missing_values(model_feature, missing_rate_array, method=\"random\", \n",
    "                                        protected_fraction=0, random_state=random_state)\n",
    "\n",
    "    valid_idx_model = ~np.isnan(model_array[:,select_feature]).all(axis=1) \n",
    "    model_array = model_array[valid_idx_model][:,select_feature]\n",
    "    model_label = y_model[valid_idx_model]\n",
    "\n",
    "    valid_idx = ~np.isnan(calibration_array[:,select_feature]).all(axis=1)  \n",
    "    calibration_array = calibration_array[valid_idx][:,select_feature]\n",
    "    calibration_label = y_calibration[valid_idx]\n",
    "\n",
    "    # add part of model_array into train_array\n",
    "    np.random.seed(42)\n",
    "    add_count = int((i / 2) * len(calibration_array))\n",
    "    add_model_idx = np.random.choice(len(model_array), add_count, replace=False)\n",
    "\n",
    "    selected_model_array = model_array[add_model_idx]\n",
    "    selected_model_label = model_label[add_model_idx]\n",
    "\n",
    "    calibration_array = np.vstack((calibration_array, selected_model_array))\n",
    "    calibration_label = np.hstack((calibration_label, selected_model_label)) \n",
    "    \n",
    "    valid_idx_regularization = ~np.isnan(regularization_array[:,select_feature]).all(axis=1)  \n",
    "    regularization_array = regularization_array[valid_idx_regularization][:,select_feature]\n",
    "\n",
    "    valid_idx_test = ~np.isnan(test_array[:,select_feature]).all(axis=1) \n",
    "    test_array = test_array[valid_idx_test][:,select_feature]\n",
    "    test_label = y_test[valid_idx_test]\n",
    "\n",
    "    print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "    test_results_array = get_bootstrap_KNN_score_gpu(calibration_array, test_array, regularization_array, \n",
    "                                                     calibration_label, Pprior, w_calibration, \n",
    "                                                     n_calibration_in_window, frac_regularization_in_window, \n",
    "                                                     normalization, impute, mi_scaling, \n",
    "                                                     n_bootstrap, batch_size)\n",
    "\n",
    "    np.save(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}.npy', test_results_array)\n",
    "\n",
    "    test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_numtool_{condition_string}.npy')\n",
    "\n",
    "    P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "    evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result(test_results_array,\n",
    "                                                                                                    test_label, \n",
    "                                                                                                    p_value, \n",
    "                                                                                                    Pprior, \n",
    "                                                                                                    logbase, \n",
    "                                                                                                    category = f\"{i/2:.1f}\", \n",
    "                                                                                                    show_plot=True, \n",
    "                                                                                                    save_name=condition_string)\n",
    "\n",
    "    combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "    pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "    benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "    mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "        \n",
    "    print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "    print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cd494-0042-4577-a7e8-b48555d97795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import colorsys\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def lighten_color(color, amount=0.5):\n",
    "    \"\"\"make color brighter, the larger the brighter0~1\"\"\"\n",
    "    try:\n",
    "        c = mcolors.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    h, l, s = colorsys.rgb_to_hls(*mcolors.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(h, 1 - amount * (1 - l), s)\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "pal = sns.color_palette(\"dark\", n_colors=len(combine_data[\"Category\"].unique()))\n",
    "g = sns.FacetGrid(combine_data, row=\"Category\", hue=\"Category\", aspect=12, height=0.6, palette=pal)\n",
    "\n",
    "g.map(sns.kdeplot, \"Score\", bw_adjust=.6, clip_on=False, fill=True, alpha=0.8, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=1, bw_adjust=.6)\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "dark_gray = '0.3'\n",
    "for ax, (cat, _) in zip(g.axes.flat, combine_data.groupby(\"Category\")):\n",
    "    inset_ax = inset_axes(\n",
    "        ax,\n",
    "        width=\"100%\", height=\"30%\",\n",
    "        bbox_to_anchor=(0, 0.15, 1, 0.5),  # (x0, y0, width, height) in axes fraction\n",
    "        bbox_transform=ax.transAxes,\n",
    "        loc=\"lower left\",\n",
    "        borderpad=0\n",
    "    )\n",
    "\n",
    "    orig_color = pal[list(combine_data[\"Category\"].unique()).index(cat)]\n",
    "    light_color = lighten_color(orig_color, 0.2)\n",
    "    \n",
    "    sns.boxplot(\n",
    "        x=\"Score\",\n",
    "        data=combine_data[combine_data[\"Category\"] == cat],\n",
    "        ax=inset_ax,\n",
    "        color=light_color,\n",
    "        showcaps=True,\n",
    "        showfliers=False,\n",
    "        whiskerprops={'color': dark_gray, 'linewidth': 1.5, 'zorder': 2},\n",
    "        capprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "        medianprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "        boxprops={'alpha': 0.7, 'zorder': 2, 'edgecolor': dark_gray, 'linewidth': 1.5},\n",
    "    )\n",
    "    inset_ax.set_xlim(ax.get_xlim())\n",
    "    inset_ax.axis(\"off\")\n",
    "\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.05, 0.15, f\"{label}x\", fontweight=\"bold\", color=color, fontsize=14,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"Category\")\n",
    "\n",
    "g.figure.subplots_adjust(hspace=-.6)\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.set_xlabels(\"Evidence strength (LLR)\", fontsize=14)\n",
    "g.despine(bottom=True, left=True)\n",
    "\n",
    "plt.savefig(\"Fig2H_with_box.svg\", format=\"svg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaccd0a-aa4d-4c09-b332-af332ba727c0",
   "metadata": {},
   "source": [
    "# P-KNN vs best underlying tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fcaa9-91b9-46ce-8b26-a6f1a874bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "from P_KNN_GPU import get_bootstrap_KNN_score_gpu, get_P_KNN_ACMG_score, evaluate_result_1D\n",
    "import copy\n",
    "\n",
    "#Parameter setting\n",
    "Pprior = 0.0441 \n",
    "w_calibration = None\n",
    "n_calibration_in_window = 100\n",
    "frac_regularization_in_window = 0.03\n",
    "batch_size = 512 # 4096 for A100, if V100, use 512\n",
    "normalization = None\n",
    "impute = False\n",
    "mi_scaling = False\n",
    "n_bootstrap = 100\n",
    "\n",
    "p_value = 0.05\n",
    "logbase = 1124\n",
    "\n",
    "best_mean_evidence_strength = 0\n",
    "mean_evidence_strength_list = []\n",
    "\n",
    "i=1  \n",
    "select_feature = i\n",
    "condition_string = i\n",
    "\n",
    "valid_test_idx = ~np.isnan(test_feature[:,select_feature])\n",
    "test_array = test_feature[valid_test_idx][:,select_feature].reshape(-1, 1)\n",
    "test_label = copy.deepcopy(y_test[valid_test_idx])\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Tool {condition_string}\")\n",
    "print(f\"calibration size: {calibration_array.shape[0]}, test size: {test_array.shape[0]}\")\n",
    "\n",
    "test_results_array = np.load(f'/gpfs/home/pl2948/VariantInterpretation/KNNTestResultArrays/Simulation_singletool_{condition_string}.npy')\n",
    "\n",
    "P_KNN_pathogenic, P_KNN_benign, ACMG_scores = get_P_KNN_ACMG_score(test_results_array, p_value, Pprior, logbase)\n",
    "\n",
    "evidence_strength_data, pathogenic_calibration_dict, benign_calibration_dict = evaluate_result_1D(test_results_array,\n",
    "                                                                                                  test_array,\n",
    "                                                                                                  test_label, \n",
    "                                                                                                  p_value, \n",
    "                                                                                                  Pprior, \n",
    "                                                                                                  logbase, \n",
    "                                                                                                  category = condition_string, \n",
    "                                                                                                  show_plot=True, \n",
    "                                                                                                  save_name=None)\n",
    "\n",
    "\n",
    "combine_data = pd.concat([combine_data, evidence_strength_data], ignore_index=True)\n",
    "\n",
    "mean_evidence_strength = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean() + evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "\n",
    "pathogenic_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Pathogenic variants']['Score'].mean()\n",
    "benign_evidence_mean = evidence_strength_data[evidence_strength_data['Label']=='Benign variants']['Score'].mean()\n",
    "mean_evidence_strength = (pathogenic_evidence_mean + benign_evidence_mean)/2\n",
    "\n",
    "print(\"pathogenic evidence mean\", f\"{pathogenic_evidence_mean:.3f}\")\n",
    "print(\"benign evidence mean\", f\"{benign_evidence_mean:.3f}\")\n",
    "mean_evidence_strength_list.append(mean_evidence_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e7955-e79f-4674-a690-a089250769ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "combine_data = combine_data[(\n",
    "    combine_data['Category']==1) | (\n",
    "    combine_data['Category']=='0.0')]\n",
    "\n",
    "## violin plot\n",
    "sns.set(style=\"ticks\")\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "ax = sns.violinplot(\n",
    "    x=\"Category\",\n",
    "    y=\"Score\", \n",
    "    hue=\"Label\",   # Pathogenic and Benign \n",
    "    data=combine_data, \n",
    "    split=True,   # on each side of violin\n",
    "    inner=\"box\", \n",
    "    palette={\"Pathogenic variants\": \"red\", \"Benign variants\": \"blue\"},\n",
    "    alpha=0.6, \n",
    "    density_norm='area',\n",
    "    hue_order=['Pathogenic variants', 'Benign variants']\n",
    ")\n",
    "\n",
    "dark_gray = '0.3'\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"Category\", y=\"Score\", hue=\"Label\", data=combine_data,\n",
    "    showcaps=True,  \n",
    "    showfliers=False,\n",
    "    palette={\"Pathogenic variants\": \"pink\", \"Benign variants\": \"#bae0f5\"},\n",
    "    width=0.1, dodge=True, ax=ax,\n",
    "    whiskerprops={'color': dark_gray, 'linewidth': 1.5, 'zorder': 2},\n",
    "    capprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    medianprops={'color': dark_gray, 'linewidth': 1.5},\n",
    "    boxprops={'zorder': 2, 'edgecolor': dark_gray, 'linewidth': 1.5},\n",
    "    hue_order=['Pathogenic variants', 'Benign variants']\n",
    "\n",
    ")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "n_hue = combine_data[\"Label\"].nunique() \n",
    "ax.legend(handles[:n_hue], labels[:n_hue], loc=\"upper right\", fontsize=12)\n",
    "\n",
    "plt.legend(handles, ['Pathogenic variants', 'Benign variants'], fontsize=12, loc='lower center', bbox_to_anchor=(0.45, -0.02))\n",
    "# plt.legend(handles, ['                                   ', ''], fontsize=12, loc='lower center', bbox_to_anchor=(0.45, -0.02))\n",
    "\n",
    "category_labels = [\"Best individual tool\", \"P-KNN\"]\n",
    "plt.xticks(ticks=range(len(category_labels)), labels=category_labels, fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Evidence strength (LLR)\", fontsize=14)\n",
    "plt.yticks([-8, -4, 0, 4, 8], fontsize=14)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.savefig(\"Fig2E.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b15e1-20a5-4da1-bbae-7c59f0f3ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
